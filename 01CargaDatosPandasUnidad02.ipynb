{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Unidad 02 - Sesi√≥n 01 - Semana 04: Carga de Datos\n",
        "\n",
        "- **Materia:** Programaci√≥n para Anal√≠tica Descriptiva y Predictiva\n",
        "- **Unidad 02:** An√°lisis Descriptivo\n",
        "- **Tema 01:** Recoleci√≥n de Datos\n",
        "- **Profesor:** Dr. Vicente Garc√≠a Jim√©nez\n",
        "- **Objetivo:** En esta sesi√≥n profundizaremos sobre el tema de la carga de datos con Pandas. Aunque en clases pasadas vimos algunos ejemplos sencillos sobre c√≥mo leer datos usando `pd.read*()`, esta vez veremos los problemas m√°s comunes que pueden existir al cargar un archivo y c√≥mo abordarlos.\n",
        "\n",
        "Como se pudo ver en la diapositiva, Pandas permite cargar diversos formatos de archivo cuyos datos pueden considerarse *tabulares*. Empezaremos por el formato m√°s popular que es **CSV** y por similitud con este tipo los archivos de **Excel**\n",
        "\n",
        "\n",
        "¬°Recuerda que es importante conectar tu Colab y tambi√©n el Drive!\n",
        "\n",
        "Para poder ejecutar este *notebook* es importante que hayas colocado los archivos de trabajo en `drive/MyDrive/Unidad02/`\n"
      ],
      "metadata": {
        "id": "B9NUsRR8X4CQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sintaxis B√°sica de Pandas**\n",
        "\n",
        "Para cargar un archivo, de los formatos mencionados en la diapositiva, es importante que primero se importe la biblioteca de pandas:\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "# Se importa la biblioteca de Pandas y se le asigna a un alias que es pd\n",
        "import pandas as pd\n",
        "```\n",
        "\n",
        "Una vez realizado lo anterior ya se pueden usar funciones de lectura acorde al tipo de archivos.\n",
        "\n",
        "En general, la sintaxis b√°sica es la siguiente `df=pd.read_tipoformato(par√°metros)`, donde `df` es una variable de tipo `dataframe` y `tipoformato`puede ser sustituido por algunas de las siguientes palabras:\n",
        "\n",
        "*   csv: `df=pd.read_csv()`\n",
        "*   excel: `df=pd.read_excel()`\n",
        "*   json: `df=pd.read_json()`\n",
        "*   sql: `df=pd.read_sql()`\n",
        "*   parquet: `df=pd.read_parquet()`\n",
        "*   txt: `df=pd.read_txt()`\n",
        "* y otros m√°s!\n",
        "\n",
        "El objetivo es construir dataframe que se caracteriza por tener la siguiente estructura:\n",
        "\n",
        "\n",
        "*   Columnas\n",
        "*   Filas\n",
        "* √åndice\n",
        "* Cada columna un nombre\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oYe6XA9fcoJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CSV**\n",
        "\n",
        "El CSV (Comma-Separted Values) es un formato de archivo de texto simple que se utiliza para almacenar datos estructurados en forma de tabla. Cada l√≠nea del archivo representa una l√≠nea, y los valores de cada columna est√°n separados por comas (`,`), u otros delimitadors como punto y coma (`;`), o inclusive un tabulador.\n",
        "\n",
        "Un ejemplo sencillo del contenido de un archivo CSV es el siguiente:\n",
        "\n",
        "**Nombre,Edad,Ciudad**\n",
        "\n",
        "Ana,30,Madrid\n",
        "\n",
        "Luis,40,Barcelona\n",
        "\n",
        "Mar√≠a,25,Valencia\n",
        "\n",
        "En este caso, observamos que la **Fila 1** contiene los nombres de las columnas (**Encabezados**) y las **filas siguientes** los valores de los datos.\n",
        "\n",
        "A lo largo de las siguientes secciones veremos diversos ejemplos para leer un archivo `csv`,as√≠ como las diferentes estrategias cuando estos presentan ciertas caracter√≠sticas que son necesarias abordar para obtener un `dataframe` apropiado para el AD y el AED.\n",
        "\n"
      ],
      "metadata": {
        "id": "f-im_BlJa2an"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Lectura con diversos s√≠mbolos separadores*\n",
        "\n",
        "**Ejemplo 1:** Algunos `csv` emplean diferentes s√≠mbolos como separadores.En la siguiente celda se lee un archivo que est√° separado por comas. Este archivo tiene 6 columnas. Observa que autom√°ticament se asigna un √≠ndice a cada fila"
      ],
      "metadata": {
        "id": "y-ot3A6C3oP6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXjoz-shXy6O",
        "outputId": "01b9301b-86db-4d27-c23c-415b04fa43b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      time                                 place magType  mag  \\\n",
            "0  2018-10-13 11:10:23.560         262km NW of Ozernovskiy Rusia     mww  6.7   \n",
            "1  2018-10-13 04:34:15.580            25km E of Bitung Indonesia     mww  5.2   \n",
            "2  2018-10-13 00:13:46.220              42km WNW of Sola Vanuatu     mww  5.7   \n",
            "3  2018-10-12 21:09:49.240  13km E of Nueva Concepcion Guatemala     mww  5.7   \n",
            "4  2018-10-12 02:52:03.620    128km SE of Kimbe Papua New Guinea     mww  5.6   \n",
            "\n",
            "   alert  tsunami  \n",
            "0  green        1  \n",
            "1  green        0  \n",
            "2  green        0  \n",
            "3  green        0  \n",
            "4  green        1  \n"
          ]
        }
      ],
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex01.csv\")\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Ejemplo 2:** Para la lectura de una archivo que utiliza como seperador el punto y coma es necesario indicar en la instrucci√≥n dicho s√≠mbolo. En caso de no hacerlo el archivo cargado no se ajustar√° a lo esperado.\n",
        "\n",
        "Para indicar el s√≠mbolo separador se usa el par√°metro `sep`, el cual, es una variable que almacena el s√≠mbolo o tambi√©n una expresi√≥n regular.\n",
        "\n",
        "En el siguiente ejemplo ejecuta la versi√≥n en la que se indica el separador y posteriormente en la que se omite. Observa lo que sucede y apoyate de la instrucci√≥n `df.shape`."
      ],
      "metadata": {
        "id": "6w6n6XyzTBhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene punto y coma\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex02.csv\",sep=';')\n",
        "\n",
        "#No se indica el separador\n",
        "#df = pd.read_csv(\"drive/MyDrive/Unidad02/ex02.csv\")\n",
        "\n",
        "#imprimimos las primeras 3 filas\n",
        "print(df.head(3))\n",
        "#df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5AV0KVQUA4A",
        "outputId": "a1db219b-dc85-44b6-c434-248918245e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      time                            place magType  mag  \\\n",
            "0  2018-10-13 11:10:23.560  262km NW of Ozernovskiy, Russia     mww  6.7   \n",
            "1  2018-10-13 04:34:15.580      25km E of Bitung, Indonesia     mww  5.2   \n",
            "2  2018-10-13 00:13:46.220        42km WNW of Sola, Vanuatu     mww  5.7   \n",
            "\n",
            "   alert  tsunami  \n",
            "0  green        1  \n",
            "1  green        0  \n",
            "2  green        0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Ejemplo 3:** Otra situaci√≥n es que el separador es el espacio en blanco. Sin embargo, debido a que puede ser uno o varios espacios en blancos, es posible apoyarse en las expresiones regulares para indicar en `sep` esta situaci√≥n.\n",
        "\n",
        "El archivo ex03.csv contiene los siguientes elementos. En el c√≥digo que se proporciona se escribe una expresi√≥n regular para indicar que el separador puede ser uno o m√°s espacios en blanco (`\\s+`).\n",
        "\n",
        "En la siguiente imagen se muestra el contenido del archivo `ex03.csv`.\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "JXILB9BrWuou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex03.csv\", sep=\"\\s+\")\n",
        "\n",
        "#imprimimos las primeras 3 filas\n",
        "print(df.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WMqZ0UQYmoP",
        "outputId": "0014d439-140b-4d29-8308-f87797713d44"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     A         B         C         D\n",
            "0  aaa -0.264438 -1.026059 -0.619500\n",
            "1  bbb  0.927272  0.302904 -0.032399\n",
            "2  ccc -0.264273 -0.386314 -0.217601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 4:** Es posible que el archivo csv tenga m√∫ltiples separadores. Para ello, usamos tambi√©n las expresiones regulares.\n",
        "\n",
        "El archivo ex06.csv contiene la siguiente informaci√≥n:\n",
        "\n",
        "ID|Nombre;Edad,Ciudad\n",
        "1|Ana;23,Madrid\n",
        "2|Luis;30,Barcelona\n",
        "3|Mar√≠a;25,Valencia\n",
        "\n",
        "Aqu√¨ hay tres tipos de separadores diferentes: `|`, `;` y `,`. Veamos el ejemplo:"
      ],
      "metadata": {
        "id": "o4XlAvHRNVYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex06.csv\", sep=\"[\\|,;]\", engine=\"python\")\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjFbMYlJN5gs",
        "outputId": "da4d6a61-177b-47cd-80e1-4a14f41d51e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID Nombre  Edad     Ciudad\n",
            "0   1    Ana    23     Madrid\n",
            "1   2   Luis    30  Barcelona\n",
            "2   3  Mar√≠a    25   Valencia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Encabezados*\n",
        "\n",
        "En AD, AED y Machine Learning, siempre es deseable que los archivos tengan una fila (encabezado) que representa los nombres de cada columna (variable). Sin embargo, esto a veces no es as√≠. Por lo tanto es importante especificar que el archivo no tiene un encabezado. Esto se hace por medio de `header=None`.\n",
        "\n",
        "\n",
        "**Ejemplo 1:** En el siguiente ejemplo ejecuta la versi√≥n donde se indica que no existe un encabezado y la otra donde se omite. Observa lo que sucede."
      ],
      "metadata": {
        "id": "xNN7TI7qeVIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex04.csv\", header=None)\n",
        "\n",
        "#No se especifica que el archivo no contiene un encabezado\n",
        "#df = pd.read_csv(\"drive/MyDrive/Unidad02/ex04.csv\")\n",
        "\n",
        "#imprimimos las primeras 3 filas\n",
        "print(df.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRr62gB9fcf5",
        "outputId": "67ce6a8e-0a26-4e4d-a5b3-3054221ac605"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         0                              1    2    3      4  5\n",
            "0  2018-10-13 11:10:23.560  262km NW of Ozernovskiy Rusia  mww  6.7  green  1\n",
            "1  2018-10-13 04:34:15.580     25km E of Bitung Indonesia  mww  5.2  green  0\n",
            "2  2018-10-13 00:13:46.220       42km WNW of Sola Vanuatu  mww  5.7  green  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Ejemplo 2:** Si no queremos que Pandas le asigne un nombre por default a las columnas, entonces, podemos especificar los nombres por medio del par√°metro `names=lista`. En este caso, se omite el par√°metro `header`.\n",
        "\n",
        "En el siguiente ejemplo se muestran dos formas de hacer lo anterior."
      ],
      "metadata": {
        "id": "8TYQeQKCrkVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Primera version\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex04.csv\",\n",
        "                 names=[\"time\",\"place\",\"magType\",\"mag\",\"alert\",\"tsunami\"])\n",
        "\n",
        "#Segunda versi√≥n - declaramos una variable de tipo lista con los nombres\n",
        "#mynames=[\"time\",\"place\",\"magType\",\"mag\",\"alert\",\"tsunami\"]\n",
        "#df = pd.read_csv(\"drive/MyDrive/Unidad02/ex04.csv\", names=mynames)\n",
        "\n",
        "\n",
        "#imprimimos las primeras 3 filas\n",
        "print(df.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_gT50IQsY4z",
        "outputId": "87e8dc3f-d7f5-47a7-cb26-1c894800398c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      time                          place magType  mag  alert  \\\n",
            "0  2018-10-13 11:10:23.560  262km NW of Ozernovskiy Rusia     mww  6.7  green   \n",
            "1  2018-10-13 04:34:15.580     25km E of Bitung Indonesia     mww  5.2  green   \n",
            "2  2018-10-13 00:13:46.220       42km WNW of Sola Vanuatu     mww  5.7  green   \n",
            "\n",
            "   tsunami  \n",
            "0        1  \n",
            "1        0  \n",
            "2        0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Ejemplo 3:** Si el csv ya tiene encabezados, puedes omitir el encabezado original y usar los nueevos nombres. Para ello, usaremos el par√°metro `skiprows=lista con indices de filas a ignorar`.\n",
        "\n",
        "En el siguiente ejemplo leemos er archivo `ex01.csv' que contiene un encabezado.  Crearemos una variable que contendr√° los nuevos nombres que sustituir√°n a los originales y asignamos `skiprows=1`.\n",
        "\n",
        "Ejecuta el c√≥digo eliminando `skiprows=1` y observa lo que sucede.\n"
      ],
      "metadata": {
        "id": "5M-tcbOH46tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "nuevos_nombres = [\"tiempo_nuevo\",\"lugar_nuevo\",\"tipo_magnitud_nuevo\",\"magnitud_nuevo\",\"alerta_nuevo\",\"tsu_nuevo\"]\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex01.csv\", names = nuevos_nombres,skiprows=1)\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swX9sl4-51fy",
        "outputId": "54816c5a-94b4-46eb-8e87-777b3eaa31e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              tiempo_nuevo                           lugar_nuevo  \\\n",
            "0  2018-10-13 11:10:23.560         262km NW of Ozernovskiy Rusia   \n",
            "1  2018-10-13 04:34:15.580            25km E of Bitung Indonesia   \n",
            "2  2018-10-13 00:13:46.220              42km WNW of Sola Vanuatu   \n",
            "3  2018-10-12 21:09:49.240  13km E of Nueva Concepcion Guatemala   \n",
            "4  2018-10-12 02:52:03.620    128km SE of Kimbe Papua New Guinea   \n",
            "\n",
            "  tipo_magnitud_nuevo  magnitud_nuevo alerta_nuevo  tsu_nuevo  \n",
            "0                 mww             6.7        green          1  \n",
            "1                 mww             5.2        green          0  \n",
            "2                 mww             5.7        green          0  \n",
            "3                 mww             5.7        green          0  \n",
            "4                 mww             5.6        green          1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Ejemplo 4:** Existen conjunto de datos donde el n√∫mero de columnas es mayor a 2,000. En algunos datos este n√∫mero puede ser de 54,686,452 (columnas). Vea el caso del conjunto de datos kdd2012 en el repositorio [LIBSVM Data](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#kdd2012).\n",
        "\n",
        "Algunos repositorios proveen un archivo de texto con los nombres de las columnas, en donde, con un nombre por l√≠nea. Si esto es as√≠ podemos leer dicho archivo de texto y guardar cada nombr en una lista."
      ],
      "metadata": {
        "id": "HEC4hXum8GEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar nombres de columnas desde un archivo de texto\n",
        "with open(\"drive/MyDrive/Unidad02/columnas.txt\", \"r\") as f:\n",
        "    nombres_columnas = [line.strip() for line in f]\n",
        "\n",
        "# Leer el CSV y asignar los nombres\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex04.csv\", names=nombres_columnas, header=None)\n",
        "\n",
        "# Mostrar las primeras filas\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ0VsgER-PF-",
        "outputId": "ed9c4b50-b5e0-432f-c19a-8b214858788c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  time_txt                             place_txt magType_txt  \\\n",
            "0  2018-10-13 11:10:23.560         262km NW of Ozernovskiy Rusia         mww   \n",
            "1  2018-10-13 04:34:15.580            25km E of Bitung Indonesia         mww   \n",
            "2  2018-10-13 00:13:46.220              42km WNW of Sola Vanuatu         mww   \n",
            "3  2018-10-12 21:09:49.240  13km E of Nueva Concepcion Guatemala         mww   \n",
            "4  2018-10-12 02:52:03.620    128km SE of Kimbe Papua New Guinea         mww   \n",
            "\n",
            "   mag_txt alert_txt  tsunami_txt  \n",
            "0      6.7     green            1  \n",
            "1      5.2     green            0  \n",
            "2      5.7     green            0  \n",
            "3      5.7     green            0  \n",
            "4      5.6     green            1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Ejemplo 5:** Una segunda opci√≥n es generar los nombres autom√°ticamente con un prefijo y un √≠ndice. En el siguiente ejemplo, primero se lee el archivo y posteriormente se modifica los nombres de las columnas con `df.columns`, el cual almacena los nombres de las columnas del `dataframe`.\n",
        "\n",
        "Al hacer `df.columns = [...]`,reemplazamos los nombres originles por los generados"
      ],
      "metadata": {
        "id": "calIxZPb_VAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Leer el CSV sin encabezado\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex04.csv\", header=None)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# Generar nombres de columnas autom√°ticamente\n",
        "#se genera una lista [\"Columna_0\", \"Columna_1\", \"Columna_2\", ..., \"Columna_N\"]\n",
        "df.columns = [f\"MiColumna_{i}\" for i in range(df.shape[1])]\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7bZNnNvAqWq",
        "outputId": "28783f47-617b-41a2-9988-261b9201f8c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         0                                     1    2    3  \\\n",
            "0  2018-10-13 11:10:23.560         262km NW of Ozernovskiy Rusia  mww  6.7   \n",
            "1  2018-10-13 04:34:15.580            25km E of Bitung Indonesia  mww  5.2   \n",
            "2  2018-10-13 00:13:46.220              42km WNW of Sola Vanuatu  mww  5.7   \n",
            "3  2018-10-12 21:09:49.240  13km E of Nueva Concepcion Guatemala  mww  5.7   \n",
            "4  2018-10-12 02:52:03.620    128km SE of Kimbe Papua New Guinea  mww  5.6   \n",
            "\n",
            "       4  5  \n",
            "0  green  1  \n",
            "1  green  0  \n",
            "2  green  0  \n",
            "3  green  0  \n",
            "4  green  1  \n",
            "               MiColumna_0                           MiColumna_1 MiColumna_2  \\\n",
            "0  2018-10-13 11:10:23.560         262km NW of Ozernovskiy Rusia         mww   \n",
            "1  2018-10-13 04:34:15.580            25km E of Bitung Indonesia         mww   \n",
            "2  2018-10-13 00:13:46.220              42km WNW of Sola Vanuatu         mww   \n",
            "3  2018-10-12 21:09:49.240  13km E of Nueva Concepcion Guatemala         mww   \n",
            "4  2018-10-12 02:52:03.620    128km SE of Kimbe Papua New Guinea         mww   \n",
            "\n",
            "   MiColumna_3 MiColumna_4  MiColumna_5  \n",
            "0          6.7       green            1  \n",
            "1          5.2       green            0  \n",
            "2          5.7       green            0  \n",
            "3          5.7       green            0  \n",
            "4          5.6       green            1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*Omitir Filas y Columnas*\n",
        "\n",
        "Pandas permite omitir filas y columnas al leer un archivo CSV usando los par√°metros skiprows, skipfooter y usecols.\n",
        "\n",
        "**Ejemplo 1:** Omitir las primeras `n` filas (`skiprows`)\n",
        "Si un archivo CSV tiene filas iniciales innecesarias, puedes ignorarlas con skiprows.\n"
      ],
      "metadata": {
        "id": "5s5vvlPhE2Vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "#Se omiten las 2 primeras filas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex01.csv\", skiprows=2)\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL4aA4nQJVMn",
        "outputId": "8b103fe0-a496-4cf7-f2a5-d2d5b88bfa73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   2018-10-13 04:34:15.580            25km E of Bitung Indonesia  mww  5.2  \\\n",
            "0  2018-10-13 00:13:46.220              42km WNW of Sola Vanuatu  mww  5.7   \n",
            "1  2018-10-12 21:09:49.240  13km E of Nueva Concepcion Guatemala  mww  5.7   \n",
            "2  2018-10-12 02:52:03.620    128km SE of Kimbe Papua New Guinea  mww  5.6   \n",
            "\n",
            "   green  0  \n",
            "0  green  0  \n",
            "1  green  0  \n",
            "2  green  1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 2**: Omitir filas espec√≠ficas (`skiprows` con lista)\n",
        "\n",
        "Si quieres omitir filas espec√≠ficas, puedes pasar una lista de √≠ndices. En el siguiente ejemplo se omiten las filas 1 y 3 (√≠ndices 1 y 3, empezando desde 0)"
      ],
      "metadata": {
        "id": "8FnUyWOHJjD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "# omiten las filas 1 y 3 (√≠ndices 1 y 3, empezando desde 0)\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex01.csv\", skiprows=[1,3])\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PimnVQqgJq8d",
        "outputId": "97e66e63-658f-4787-da2b-e11ee4939f55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      time                                 place magType  mag  \\\n",
            "0  2018-10-13 04:34:15.580            25km E of Bitung Indonesia     mww  5.2   \n",
            "1  2018-10-12 21:09:49.240  13km E of Nueva Concepcion Guatemala     mww  5.7   \n",
            "2  2018-10-12 02:52:03.620    128km SE of Kimbe Papua New Guinea     mww  5.6   \n",
            "\n",
            "   alert  tsunami  \n",
            "0  green        0  \n",
            "1  green        0  \n",
            "2  green        1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 3**: Omitir las √∫ltimas `n` filas (`skipfooter`)\n",
        "\n",
        "Si el csv tiene datos irrelevantes al final, se puede usar `skipfooter`. En el siguiente ejemplo se omite la √∫ltima fila.\n",
        "\n",
        "Observa tambi√©n que se usa el par√°metro `engine=\"python\"`, el cual le indica a Pandas que se debe de usar l motor de an√°lisis de archivos de texto de Python, en lugar del motor determinado basado en el lenguaje C.\n",
        "\n"
      ],
      "metadata": {
        "id": "9c16SG6kKeSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "# omiten las filas 1 y 3 (√≠ndices 1 y 3, empezando desde 0)\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex01.csv\", skipfooter=1,engine=\"python\")\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br8TP-dpKyTF",
        "outputId": "9806c74f-717d-428c-91b4-9a66e68880c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      time                                 place magType  mag  \\\n",
            "0  2018-10-13 11:10:23.560         262km NW of Ozernovskiy Rusia     mww  6.7   \n",
            "1  2018-10-13 04:34:15.580            25km E of Bitung Indonesia     mww  5.2   \n",
            "2  2018-10-13 00:13:46.220              42km WNW of Sola Vanuatu     mww  5.7   \n",
            "3  2018-10-12 21:09:49.240  13km E of Nueva Concepcion Guatemala     mww  5.7   \n",
            "\n",
            "   alert  tsunami  \n",
            "0  green        1  \n",
            "1  green        0  \n",
            "2  green        0  \n",
            "3  green        0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 4**: Cargar solo columnas espec√≠ficas (`usecols`)\n",
        "\n",
        "Si el csv tiene muchas columnas pero solo necesitas algunas, podemos usar `usecols`.\n"
      ],
      "metadata": {
        "id": "gJsGlCfULkx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "# C√≥digo en Pandas para cargar solo \"magType\",\"mag\",\"tsunami\"\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex01.csv\", usecols=[\"magType\",\"mag\",\"tsunami\"])\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOwE3hBSMgDz",
        "outputId": "98183458-41fd-420d-bbfe-6265de11949a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  magType  mag  tsunami\n",
            "0     mww  6.7        1\n",
            "1     mww  5.2        0\n",
            "2     mww  5.7        0\n",
            "3     mww  5.7        0\n",
            "4     mww  5.6        1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Caracteres Especiales*\n",
        "\n",
        "Algunos archivos csv puden contener caracteres especiales como acento, e√±es y otros s√≠mbolos. Para evitar problemas al leer dicho archivo o caracteres extra√±os, se requiere usar el par√°metro `encoding=\"utf-8\"`\n",
        "\n",
        "El archivo `ex07.csv`contiene la siguiente informaci√≥n:\n",
        "\n",
        "ID,Nombre,Pa√≠s,Comentario\n",
        "\n",
        "1,Ana,Espa√±a,\"Estudi√≥ en la universidad p√∫blica de Madrid\"\n",
        "\n",
        "2,Luis,M√©xico,\"Le encanta la programaci√≥n y la m√∫sica üéµ\"\n",
        "\n",
        "3,Mar√≠a,Francia,\"Habla franc√©s, ingl√©s y espa√±ol\"\n",
        "\n",
        "4,Jos√©,Brasil,\"Trabaja en S√£o Paulo\"\n",
        "\n",
        "5,Sof√≠a,Alemania,\"Investigadora en f√≠sica cu√°ntica ‚öõÔ∏è\"\n",
        "\n"
      ],
      "metadata": {
        "id": "pjMkZ0RcOp4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex07.csv\",encoding=\"utf-8\")\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5c17mPoPZKg",
        "outputId": "d49f7a0a-a131-41db-eb7d-d8561eb40511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID Nombre      Pa√≠s                                   Comentario\n",
            "0   1    Ana    Espa√±a  Estudi√≥ en la universidad p√∫blica de Madrid\n",
            "1   2   Luis    M√©xico     Le encanta la programaci√≥n y la m√∫sica üéµ\n",
            "2   3  Mar√≠a   Francia              Habla franc√©s, ingl√©s y espa√±ol\n",
            "3   4   Jos√©    Brasil                         Trabaja en S√£o Paulo\n",
            "4   5  Sof√≠a  Alemania          Investigadora en f√≠sica cu√°ntica ‚öõÔ∏è\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Valores Perdidos*\n",
        "\n",
        "Cuando los datos se exportan a CSV desde diferentes sistemas, los valores faltantes pueden especificarse con distintos s√≠mbolos.\n",
        "\n",
        "Los valores predeterminados que Pandas interpreta como NA/NaN son:\n",
        "`''`, `#N/A`, `#N/A`, `N/A`, `#NA`, `-1.#IND`, `-1.#QNAN`, `-NaN`, `-nan`, `1.#IND`, `1.#QNAN`, `N/A`, `NA`, `NULL`, `NaN`, `n/a`, `nan`, `null`.\n",
        "\n",
        "**Ejemplo 1:** El archivo ex08.csv contiene 3 valores perdidos que se identifican con el valor `NaN` y `??`. Observa que salida produce cuando se emplea la instrucci√≥n `pd.isna(df)`"
      ],
      "metadata": {
        "id": "qvMmbGcOPvDf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2sAdSh1lRy2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex08.csv\")\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())\n",
        "\n",
        "#Mostramos las celdas en las que aparece un dato perdido\n",
        "print(pd.isna(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deu6EEk0Rdyg",
        "outputId": "26893c75-df7a-4fa8-cc04-f0f86304d294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  something  a   b     c   d message\n",
            "0       one  1   2   3.0   4     NaN\n",
            "1       two  5  ??   NaN   8   world\n",
            "2     three  9  10  11.0  12     foo\n",
            "   something      a      b      c      d  message\n",
            "0      False  False  False  False  False     True\n",
            "1      False  False  False   True  False    False\n",
            "2      False  False  False  False  False    False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 02:** los caracteres `??` denotan un valor perdido, este no fue detectado como tal. Para que esto ocurra, el par√°metro `na_values` permite personalizar la lista de caracteres que se reconocer√°n como valores faltantes."
      ],
      "metadata": {
        "id": "VMqCu0c-SbDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex08.csv\",na_values=[\"??\"])\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())\n",
        "\n",
        "print(pd.isna(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a1m28IES3lu",
        "outputId": "300fe9db-ac6e-4013-d140-72f75355cdaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  something  a     b     c   d message\n",
            "0       one  1   2.0   3.0   4     NaN\n",
            "1       two  5   NaN   NaN   8   world\n",
            "2     three  9  10.0  11.0  12     foo\n",
            "   something      a      b      c      d  message\n",
            "0      False  False  False  False  False     True\n",
            "1      False  False   True   True  False    False\n",
            "2      False  False  False  False  False    False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Archivos Grandes CSV*\n",
        "\n",
        "Procesar archivos csv grandes en Pandas requiere estrategias avanzadas para optimizar memoria y velocidad. Existen diversas estrategias y aqu√≠ veremos algunas de ellas.\n",
        "\n",
        "**Ejemplo 1:** Es posible que tengas la capacidad de cargar el archivo. Sin embargo, al querer imprimir el contenido seguramente tardar√° y ocupar√° toda tu pantalla. Una opci√≥n es usar la instrucci√≥n `pd.options.display.max_rows=n√∫mero de filas`, la cual se usa para controlar el n√∫mero m√°ximo de filas que pandas muestra cuando se imprime un `dataframe`.  El efecto de usar esta instrucci√≥n es que Pandas trunca la salida si el `dataframe` tiene muchas filas, mostrando solo las primeras y √∫ltimas filas con \"...\" en el medio.\n",
        "\n",
        "El archivo ex09.csv contiene 5 columnas y 10,000 Filas. En el siguiente ejemplo `pd.options.display.max_rows=10`.\n"
      ],
      "metadata": {
        "id": "di1BSwrN7KDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "#Limitamos el n√∫mero de filas a mostrar de las 10,000\n",
        "pd.options.display.max_rows = 10\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex09.csv\")\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAitsdTb-6_O",
        "outputId": "ed601b22-e9ac-4ac5-d64e-612b8b8be762"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           one       two     three      four key\n",
            "0     0.467976 -0.038649 -0.295344 -1.824726   L\n",
            "1    -0.358893  1.404453  0.704965 -0.200638   B\n",
            "2    -0.501840  0.659254 -0.421691 -0.057688   G\n",
            "3     0.204886  1.074134  1.388361 -0.982404   R\n",
            "4     0.354628 -0.133116  0.283763 -0.837063   Q\n",
            "...        ...       ...       ...       ...  ..\n",
            "9995  2.311896 -0.417070 -1.409599 -0.515821   L\n",
            "9996 -0.479893 -0.650419  0.745152 -0.646038   E\n",
            "9997  0.523331  0.787112  0.486066  1.093156   K\n",
            "9998 -0.362559  0.598894 -1.843201  0.887292   G\n",
            "9999 -0.096376 -1.012999 -0.657431 -0.573315   0\n",
            "\n",
            "[10000 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 2:** Esta estrategia es muy sencilla y se enfoca en solo leer un parte (muestra) al especificar el n√∫mero de filas. Esto te permite una r√°pida inspecci√≥n sin cargar todo el archivo en memoria.\n",
        "\n",
        "En este ejercicio vamos a trabajar con un archivo conocido como NYC Yellow Taxi Trip Data del 2016. Debido al tama√±o de este archivo , 1.91 GB, est√° alojado en una carpeta de Dropbox."
      ],
      "metadata": {
        "id": "TAhkM6bPAp8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "#una variable que contiene la direcci√≥n donde est√° alojado el archivo\n",
        "url = \"https://www.dropbox.com/scl/fo/x4a4a3jst0z0feb8kedz7/AC-g-Xxv6CmyBaL7jeKpiEo?rlkey=pmrtbg5qlxrq397f9lcxfr6iw&dl=1\"\n",
        "\n",
        "df = pd.read_csv(url, nrows=100, sep=',', encoding=\"utf-8\")  # Leer solo 100 filas\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhgBJIbODSa5",
        "outputId": "48435434-3173-42a6-e783-16e41d7f7c42"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PK\u0003\u0004\u0014 tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
            "0      1  2016-03-01 00:00:00   2016-03-01 00:07:55                1   \n",
            "1      1  2016-03-01 00:00:00   2016-03-01 00:11:06                1   \n",
            "2      2  2016-03-01 00:00:00   2016-03-01 00:31:06                2   \n",
            "3      2  2016-03-01 00:00:00   2016-03-01 00:00:00                3   \n",
            "4      2  2016-03-01 00:00:00   2016-03-01 00:00:00                5   \n",
            "\n",
            "   trip_distance  pickup_longitude  pickup_latitude  RatecodeID  \\\n",
            "0           2.50        -73.976746        40.765152           1   \n",
            "1           2.90        -73.983482        40.767925           1   \n",
            "2          19.98        -73.782021        40.644810           1   \n",
            "3          10.78        -73.863419        40.769814           1   \n",
            "4          30.43        -73.971741        40.792183           3   \n",
            "\n",
            "  store_and_fwd_flag  dropoff_longitude  dropoff_latitude  payment_type  \\\n",
            "0                  N         -74.004265         40.746128             1   \n",
            "1                  N         -74.005943         40.733166             1   \n",
            "2                  N         -73.974541         40.675770             1   \n",
            "3                  N         -73.969650         40.757767             1   \n",
            "4                  N         -74.177170         40.695053             1   \n",
            "\n",
            "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
            "0          9.0    0.5      0.5        2.05          0.00   \n",
            "1         11.0    0.5      0.5        3.05          0.00   \n",
            "2         54.5    0.5      0.5        8.00          0.00   \n",
            "3         31.5    0.0      0.5        3.78          5.54   \n",
            "4         98.0    0.0      0.0        0.00         15.50   \n",
            "\n",
            "   improvement_surcharge  total_amount  \n",
            "0                    0.3         12.35  \n",
            "1                    0.3         15.35  \n",
            "2                    0.3         63.80  \n",
            "3                    0.3         41.62  \n",
            "4                    0.3        113.80  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 2:** Leer en bloques (`chunksize`), por lo que, en lugar de cargar el archivo completo, Pandas permite procesarlo en bloques m√°s peque√±os, evitando el colapso de memoria."
      ],
      "metadata": {
        "id": "8uXl1rugJbeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "chunk_size = 1000  # Tama√±o del bloque\n",
        "\n",
        "# Leer el archivo en bloques\n",
        "\n",
        "for chunk in pd.read_csv(\"drive/MyDrive/Unidad02/ex09.csv\", sep=',', encoding=\"utf-8\", chunksize=chunk_size):\n",
        "  print(f\"Procesando bloque de {chunk_size} filas:\")\n",
        "  print(chunk.head())\n",
        "  print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74iVFTnTJrWl",
        "outputId": "adffbc19-5cdd-4fd4-fb6e-cb20e6eca314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando bloque de 1000 filas:\n",
            "        one       two     three      four key\n",
            "0  0.467976 -0.038649 -0.295344 -1.824726   L\n",
            "1 -0.358893  1.404453  0.704965 -0.200638   B\n",
            "2 -0.501840  0.659254 -0.421691 -0.057688   G\n",
            "3  0.204886  1.074134  1.388361 -0.982404   R\n",
            "4  0.354628 -0.133116  0.283763 -0.837063   Q\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "1000  0.467976 -0.038649 -0.295344 -1.824726   T\n",
            "1001 -0.358893  1.404453  0.704965 -0.200638   J\n",
            "1002 -0.501840  0.659254 -0.421691 -0.057688   R\n",
            "1003  0.204886  1.074134  1.388361 -0.982404   S\n",
            "1004  0.354628 -0.133116  0.283763 -0.837063   B\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "2000  0.467976 -0.038649 -0.295344 -1.824726   1\n",
            "2001 -0.358893  1.404453  0.704965 -0.200638   H\n",
            "2002 -0.501840  0.659254 -0.421691 -0.057688   F\n",
            "2003  0.204886  1.074134  1.388361 -0.982404   L\n",
            "2004  0.354628 -0.133116  0.283763 -0.837063   E\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "3000  0.467976 -0.038649 -0.295344 -1.824726   H\n",
            "3001 -0.358893  1.404453  0.704965 -0.200638   Y\n",
            "3002 -0.501840  0.659254 -0.421691 -0.057688   0\n",
            "3003  0.204886  1.074134  1.388361 -0.982404   Z\n",
            "3004  0.354628 -0.133116  0.283763 -0.837063   U\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "4000  0.467976 -0.038649 -0.295344 -1.824726   H\n",
            "4001 -0.358893  1.404453  0.704965 -0.200638   Z\n",
            "4002 -0.501840  0.659254 -0.421691 -0.057688   2\n",
            "4003  0.204886  1.074134  1.388361 -0.982404   B\n",
            "4004  0.354628 -0.133116  0.283763 -0.837063   1\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "5000  0.467976 -0.038649 -0.295344 -1.824726   1\n",
            "5001 -0.358893  1.404453  0.704965 -0.200638   Z\n",
            "5002 -0.501840  0.659254 -0.421691 -0.057688   3\n",
            "5003  0.204886  1.074134  1.388361 -0.982404   H\n",
            "5004  0.354628 -0.133116  0.283763 -0.837063   B\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "6000  0.467976 -0.038649 -0.295344 -1.824726   I\n",
            "6001 -0.358893  1.404453  0.704965 -0.200638   X\n",
            "6002 -0.501840  0.659254 -0.421691 -0.057688   A\n",
            "6003  0.204886  1.074134  1.388361 -0.982404   C\n",
            "6004  0.354628 -0.133116  0.283763 -0.837063   S\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "7000  0.467976 -0.038649 -0.295344 -1.824726   1\n",
            "7001 -0.358893  1.404453  0.704965 -0.200638   I\n",
            "7002 -0.501840  0.659254 -0.421691 -0.057688   H\n",
            "7003  0.204886  1.074134  1.388361 -0.982404   P\n",
            "7004  0.354628 -0.133116  0.283763 -0.837063   D\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "8000  0.467976 -0.038649 -0.295344 -1.824726   7\n",
            "8001 -0.358893  1.404453  0.704965 -0.200638   W\n",
            "8002 -0.501840  0.659254 -0.421691 -0.057688   C\n",
            "8003  0.204886  1.074134  1.388361 -0.982404   S\n",
            "8004  0.354628 -0.133116  0.283763 -0.837063   H\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "9000  0.467976 -0.038649 -0.295344 -1.824726   B\n",
            "9001 -0.358893  1.404453  0.704965 -0.200638   M\n",
            "9002 -0.501840  0.659254 -0.421691 -0.057688   N\n",
            "9003  0.204886  1.074134  1.388361 -0.982404   N\n",
            "9004  0.354628 -0.133116  0.283763 -0.837063   Y\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Excel**\n",
        "En esta sesi√≥n aprenderemos a cargar, explorar y manipular archivos Excel (`.xlsx`, `.xls`) en Pandas.\n",
        "\n",
        "Es posible que para poder leer archivos `.xlsx` se requiera instalar la biblioteca `openpyxl` y en el caso de `.xls` ser√≠a `xlrd`. Si esto sucede, recuerda que para instalar ambas bibliotecas en Google Colab se tendr√≠an que ejecutar las instrucciones siguientes:\n",
        "\n",
        "\n",
        "```python\n",
        "#para .xlsx\n",
        "!pip install openpyxl\n",
        "```\n",
        "y\n",
        "\n",
        "```python\n",
        "#para .xls\n",
        "!pip install xlrd\n",
        "```\n",
        "\n",
        "Existen dos funciones para leer archivos de Excel:\n",
        "\n",
        "\n",
        "\n",
        "1.  `pd.read_excel()` es la forma m√°s com√∫n de leer un archivo Excel en un DataFrame. **Es f√°cil, directo y se usa cuando solo necesitar leer una o pocas hojas**. Sin embargo, si el archivo **tiene varias hojas**, esta funci√≥n **vuelve a abrir el archivo cada vez que se usa**, lo que hace **lento el proceso de carga**.\n",
        "\n",
        "2.  `pd.ExcelFile()`, es **apropiado** si el archivo Excel tiene **varias hojas**, en lugar de abrirlo m√∫ltiples veces, **abre una vez**, por lo que es posible **extraer m√∫ltiples hojas sin volver a cargar el archivo**. No obstante, **requiere un paso extra** (`xls.parse(sheet_name)`) para **leer cada hoja** en un `dataframe`.\n",
        "\n",
        "En los siguientes ejemplos vamos a usar el archivo `ex10.xls` y `ex11.xlsx`. Ambos son iguales, contienen 4 hojas, donde `Hoja1` y `Hoja2` contienes una tabla sencilla, `source` contiene 2 celdas que indican la fuente de la informaci√≥n de la tercera hoja llamada `OECD.Stat export`. Esta √∫ltima, es una hoja con colores y celdas que no contienen informaci√≥n, as√≠ como otras configuraciones que son habituales en hojas de `Excel`."
      ],
      "metadata": {
        "id": "xH1Q4hzmKp9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *`pandas.read_excel()`: Leer Directamente un Archivo*\n",
        "\n",
        "`pd.read_excel()` es la forma m√°s com√∫n de leer un archivo Excel, principalmente si solo tiene una o pocas hojas. Esta funci√≥n requiere el par√°metro `sheet_name = nombre de la hoja`, para indicar el nombre de la hoja que queremos leer. Si el archivo tiene varias hojas y no se especifica este par√°metro, entonces s√≥lo se leera la primera hoja por defecto.\n",
        "\n",
        "Si quieres cargar todas las hojas en un solo paso, entonces, deber√°s usar el par√°metro `sheet_name = None`. Sin embargo, observa que esto no devuelve un `dataframe` sino una `variable` de tipo `diccionario`, donde las `claves`son los nombres de las hojas y los `valores`los dataframes de cada hoja.\n",
        "\n",
        "Para imprimir las hojas disponibles, se usa `variablediccionario.keys()`, la cual retornar√° un diccionario con el nombre clave de cada hoja. Para acceder al contenido de cada una de ellas, usamos la funci√≥n `variablediccionario[\"nombre de la hoja\"]`.\n",
        "\n",
        "**Ejemplo 1:** El siguiente c√≥digo ejemplifica lo siguiente: 1) se especifica el nombre de la hoja, 2)indica la columna que contiene el √≠ndice, 3) leer todas las hojas, 4) indicar qu√© columnas se quieren leer."
      ],
      "metadata": {
        "id": "uWUt5Lr3kPga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#---------------- 1)\n",
        "#OJO: aqu√≠ df es un dataframe\n",
        "df = pd.read_excel(\"drive/MyDrive/Unidad02/ex10.xls\", sheet_name=\"Hoja1\")\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "#---------------- 2)\n",
        "#Como esta tabla tiene una primera columna que representa el √≠ndice\n",
        "#podemos especificar con index_col el n√∫mero de columna que sea\n",
        "#indice.\n",
        "#Ejecuta el siguiente c√≥digo\n",
        "#Aqu√≠ df es un dataframe\n",
        "#df = pd.read_excel(\"drive/MyDrive/Unidad02/ex10.xls\", sheet_name=\"Hoja1\", index_col=0)\n",
        "\n",
        "#imprime la hoja 1\n",
        "#print(df.head())\n",
        "\n",
        "#--------------------------- 3)\n",
        "#Para leer todas las hojas usa sheet_name=None.\n",
        "#Recuerda que si no usas este par√°metro solo leer√° la primera hoja\n",
        "#Nota: hojas no es un dataframe sino un diccionario\n",
        "#hojas = pd.read_excel(\"drive/MyDrive/Unidad02/ex10.xls\", sheet_name=None)\n",
        "\n",
        "#imprime los nombres de todas las hojas\n",
        "#print(hojas.keys())\n",
        "\n",
        "#Se almacena en un data frame la Hoja2 (nombre)\n",
        "#df_hoja2 = hojas[\"Hoja2\"]\n",
        "#print(df_hoja2)\n",
        "\n",
        "\n",
        "#------------------- 4)\n",
        "#podemos leeer ciertas columnas\n",
        "\n",
        "#df = pd.read_excel(\"drive/MyDrive/Unidad02/ex10.xls\", sheet_name=\"Hoja2\", usecols=[\"B\", \"D\"])\n",
        "#print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVgqhKzCoK2l",
        "outputId": "77234d26-938a-44e0-e7f5-63c53854570c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  a   b   c   d message\n",
            "0           0  1   2   3   4   hello\n",
            "1           1  5   6   7   8   world\n",
            "2           2  9  10  11  12     foo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *`pandas.ExcelFile()`: Para Leer Varias Hojas*\n",
        "\n",
        "Si el archivo Excel tiene varias hojas, en lugar de abrirlo m√∫ltiples veces, `ExcelFile` permite abrirlo una vez y extraer m√∫ltiples hojas sin volver a cargar el archivo.\n",
        "\n",
        " `pandas.ExcelFile()` abre un archivo de Excel en un objeto. No carga todas las hojas de inmediata, solo prepara el archivo para acceder a sus hojas cuando sea necesario. Para ello, se usa `.parse(sheet_name)`que permite extraer las hojas individuales y convertirla en un `dataframe`.\n",
        "\n",
        " **Ejemplo 02:** Veremos como accedemos a las hojas del archivo `ex11.xlsx`."
      ],
      "metadata": {
        "id": "oYAFvPDSt1VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "xlsx = pd.ExcelFile(\"drive/MyDrive/Unidad02/ex10.xls\")\n",
        "\n",
        "#imprimos las hojas disponibles\n",
        "print(xlsx.sheet_names)\n",
        "\n",
        "#Leemos la primera hoja llamada Hoja1 e indicamos qu√© columna usar como √≠ndice\n",
        "\n",
        "df=xlsx.parse(sheet_name=\"Hoja1\", index_col=0)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "#La segunda hoja\n",
        "df=xlsx.parse(sheet_name=\"Hoja2\", usecols=[\"B\", \"D\"])\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjGRyn2WsFf0",
        "outputId": "c0b538fa-e203-44d5-c332-934ff3186b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hoja1', 'Hoja2', 'Source', 'OECD.Stat export']\n",
            "   a   b   c   d message\n",
            "0  1   2   3   4   hello\n",
            "1  5   6   7   8   world\n",
            "2  9  10  11  12     foo\n",
            "          B         D\n",
            "0 -0.264438 -0.619500\n",
            "1  0.927272 -0.032399\n",
            "2 -0.264273 -0.217601\n",
            "3 -0.871858  1.100491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Ejemplo con hojas complejas*\n",
        "En esta receta, importamos un archivo de Excel y abordamos algunos problemas comunes al trabajar con estos archivos: informaci√≥n extra en encabezados y pies de p√°gina, selecci√≥n de columnas espec√≠ficas, eliminaci√≥n de filas sin datos y conexi√≥n a hojas en particular.\n",
        "\n",
        "A pesar de la estructura tabular de Excel, que fomenta la organizaci√≥n de datos en filas y columnas, las hojas de c√°lculo no son conjuntos de datos y no requieren que las personas almacenen la informaci√≥n de esa manera. Incluso cuando algunos datos cumplen con esta estructura, es com√∫n encontrar informaci√≥n adicional en filas o columnas antes o despu√©s de los datos a importar. Adem√°s, los tipos de datos no siempre son evidentes para quien no cre√≥ la hoja de c√°lculo.\n",
        "\n",
        "Los que haremos es lo siguiente:\n",
        "\n",
        "- Seleccionaremos la hoja con los datos que necesitamos, pero omiteremos las columnas y filas que no queremos. Usaremos el par√°metro `sheet_name` para especificar la hoja.\n",
        "\n",
        "- Emplearemos `skiprows=4` y `skipfooter=1` para omitir las primeras cuatro filas (la primera fila est√° oculta) y la √∫ltima fila, respectivamente.\n",
        "\n",
        "- Usaremos `usecols` para obtener datos de la columna A y de las columnas C a W (la columna B est√° en blanco).\n",
        "- Tambi√©n `head` para ver las primeras filas y `shape` para obtener el n√∫mero de filas y columnas.\n"
      ],
      "metadata": {
        "id": "lmxOwljZxBTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(\"drive/MyDrive/Unidad02/ex11.xlsx\",\n",
        "                   sheet_name=\"OECD.Stat export\",\n",
        "                   skiprows=4,\n",
        "                   skipfooter=1,\n",
        "                   usecols=\"A,C:T\")\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTtWE61cyzlE",
        "outputId": "fe881ac6-1e72-4440-d4e2-753a4b6839aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         Year   2001   2002   2003   2004   2005   2006  \\\n",
            "0          Metropolitan areas    NaN    NaN    NaN    NaN    NaN    NaN   \n",
            "1              AUS: Australia     ..     ..     ..     ..     ..     ..   \n",
            "2       AUS01: Greater Sydney  43313  44008  45424  45837  45423  45547   \n",
            "3    AUS02: Greater Melbourne  40125  40894  41602  42188  41484  41589   \n",
            "4     AUS03: Greater Brisbane  37580  37564  39080  40762  42976  44475   \n",
            "\n",
            "    2007   2008   2009   2010   2011   2012   2013   2014   2015   2016  \\\n",
            "0    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
            "1     ..     ..     ..     ..     ..     ..     ..     ..     ..     ..   \n",
            "2  45880  45225  45900  45672  46535  47350  47225  48510  50075  50519   \n",
            "3  42316  40975  41384  40943  41165  41264  41157  42114  42928  42671   \n",
            "4  44635  46192  43507  42774  44166  43764  43379  43754  44388  45723   \n",
            "\n",
            "    2017   2018  \n",
            "0    NaN    NaN  \n",
            "1     ..     ..  \n",
            "2  50578  49860  \n",
            "3  43025  42674  \n",
            "4  46876  46640  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importar Datos desde Bases de Datos SQL**\n",
        "\n",
        "En este ejemplo, utilizamos las API de pymssql y mysql para leer datos desde bases de datos Microsoft SQL Server y MySQL. Tambi√©n es posible que se requiera instalar ambas API.\n",
        "\n",
        "No profundizaremos en este tema porque require aspectos de Ingenier√≠a de Datos y SQL\n",
        "\n",
        "En este ejercicio nos conectaremos a una base de datos que est√° en la nube. Para extraer los datos usaremos una consulta SQL\n",
        "\n"
      ],
      "metadata": {
        "id": "hbUuo7Wo1psk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymssql"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4l7GDjch0-Nb",
        "outputId": "d12c44f5-725b-49b8-c21e-0ffbb03a8caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymssql\n",
            "  Downloading pymssql-2.3.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.7 kB)\n",
            "Downloading pymssql-2.3.2-cp311-cp311-manylinux_2_28_x86_64.whl (4.8 MB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/4.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.4/4.8 MB\u001b[0m \u001b[31m133.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymssql\n",
            "Successfully installed pymssql-2.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install mysql-connector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mbnIn3l_1G1y",
        "outputId": "a9656657-2bdd-49bd-b304-bfa3f9e98120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mysql-connector\n",
            "  Downloading mysql-connector-2.2.9.tar.gz (11.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mysql-connector\n",
            "  Building wheel for mysql-connector (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysql-connector: filename=mysql_connector-2.2.9-cp311-cp311-linux_x86_64.whl size=247949 sha256=5a2d7fb29dbe3cf88c1746ac03a1949f1111652e86748b6f579c0c6ac6ac83c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/cd/ed/2d49e9bac69cf09382e4c7cc20a2511202b48324b87db26019\n",
            "Successfully built mysql-connector\n",
            "Installing collected packages: mysql-connector\n",
            "Successfully installed mysql-connector-2.2.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Importaci√≥n de bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pymssql\n",
        "import mysql.connector\n",
        "\n",
        "# Consulta SQL que selecciona datos de la tabla studentmath.\n",
        "query = \"SELECT studentid, school, sex, age, famsize,\\\n",
        "  medu AS mothereducation, fedu AS fathereducation,\\\n",
        "  traveltime, studytime, failures, famrel, freetime,\\\n",
        "  goout, g1 AS gradeperiod1, g2 AS gradeperiod2,\\\n",
        "  g3 AS gradeperiod3 From studentmath\"\n",
        "\n",
        "#Conexi√≥n a la base de datos SQL Server\n",
        "# use the pymssql api and read_sql to retrieve and load data from a SQL Server instance\n",
        "server = \"pdcc.c9sqqzd5fulv.us-west-2.rds.amazonaws.com\"\n",
        "user = \"pdccuser\"\n",
        "password = \"pdccpass\"\n",
        "database = \"pdcctest\"\n",
        "\n",
        "#Se establece la conexi√≥n a una base de datos SQL Server en la nube\n",
        "conn = pymssql.connect(server=server,\n",
        "                       user=user, password=password, database=database)\n",
        "\n",
        "#Ejecuci√≥n de la consulta y carga en un DataFrame\n",
        "studentmath = pd.read_sql(query,conn)\n",
        "\n",
        "#cierra la conexi√≥n con la base de datos despu√©s de obtener los datos\n",
        "conn.close()\n",
        "\n",
        "#imprimimos el dataframe\n",
        "print(studentmath.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__K5xqc70ytQ",
        "outputId": "f06bfa11-5ebd-4788-9eee-071cf55c6e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-cd20bbcfffd5>:26: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  studentmath = pd.read_sql(query,conn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  studentid school sex  age famsize  mothereducation  fathereducation  \\\n",
            "0       001     GP   F   18     GT3                4                4   \n",
            "1       002     GP   F   17     GT3                1                1   \n",
            "2       003     GP   F   15     LE3                1                1   \n",
            "3       004     GP   F   15     GT3                4                2   \n",
            "4       005     GP   F   16     GT3                3                3   \n",
            "\n",
            "   traveltime  studytime  failures  famrel  freetime  goout  gradeperiod1  \\\n",
            "0           2          2         0       4         3      4             5   \n",
            "1           1          2         0       5         3      3             5   \n",
            "2           1          2         3       4         3      2             7   \n",
            "3           1          3         0       3         2      2            15   \n",
            "4           1          2         0       4         3      2             6   \n",
            "\n",
            "   gradeperiod2  gradeperiod3  \n",
            "0             6             6  \n",
            "1             5             6  \n",
            "2             8            10  \n",
            "3            14            15  \n",
            "4            10            10  \n"
          ]
        }
      ]
    }
  ]
}