{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Unidad 02 - Sesión 01 - Semana 04: Carga de Datos\n",
        "\n",
        "- **Materia:** Programación para Analítica Descriptiva y Predictiva\n",
        "- **Unidad 02:** Análisis Descriptivo\n",
        "- **Tema 01:** Recoleción de Datos\n",
        "- **Profesor:** Dr. Vicente García Jiménez\n",
        "- **Objetivo:** En esta sesión profundizaremos sobre el tema de la carga de datos con Pandas. Aunque en clases pasadas vimos algunos ejemplos sencillos sobre cómo leer datos usando `pd.read*()`, esta vez veremos los problemas más comunes que pueden existir al cargar un archivo y cómo abordarlos.\n",
        "\n",
        "Como se pudo ver en la diapositiva, Pandas permite cargar diversos formatos de archivo cuyos datos pueden considerarse *tabulares*. Empezaremos por el formato más popular que es **CSV** y por similitud con este tipo los archivos de **Excel**\n",
        "\n",
        "\n",
        "¡Recuerda que es importante conectar tu Colab y también el Drive!\n",
        "\n",
        "Para poder ejecutar este *notebook* es importante que hayas colocado los archivos de trabajo en `drive/MyDrive/Unidad02/`\n"
      ],
      "metadata": {
        "id": "B9NUsRR8X4CQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sintaxis Básica de Pandas**\n",
        "\n",
        "Para cargar un archivo, de los formatos mencionados en la diapositiva, es importante que primero se importe la biblioteca de pandas:\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "# Se importa la biblioteca de Pandas y se le asigna a un alias que es pd\n",
        "import pandas as pd\n",
        "```\n",
        "\n",
        "Una vez realizado lo anterior ya se pueden usar funciones de lectura acorde al tipo de archivos.\n",
        "\n",
        "En general, la sintaxis básica es la siguiente `df=pd.read_tipoformato(parámetros)`, donde `df` es una variable de tipo `dataframe` y `tipoformato`puede ser sustituido por algunas de las siguientes palabras:\n",
        "\n",
        "*   csv: `df=pd.read_csv()`\n",
        "*   excel: `df=pd.read_excel()`\n",
        "*   json: `df=pd.read_json()`\n",
        "*   sql: `df=pd.read_sql()`\n",
        "*   parquet: `df=pd.read_parquet()`\n",
        "*   txt: `df=pd.read_txt()`\n",
        "* y otros más!\n",
        "\n",
        "El objetivo es construir dataframe que se caracteriza por tener la siguiente estructura:\n",
        "\n",
        "\n",
        "*   Columnas\n",
        "*   Filas\n",
        "* Ìndice\n",
        "* Cada columna un nombre\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oYe6XA9fcoJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CSV**\n",
        "\n",
        "El CSV (Comma-Separted Values) es un formato de archivo de texto simple que se utiliza para almacenar datos estructurados en forma de tabla. Cada línea del archivo representa una línea, y los valores de cada columna están separados por comas (`,`), u otros delimitadors como punto y coma (`;`), o inclusive un tabulador.\n",
        "\n",
        "Un ejemplo sencillo del contenido de un archivo CSV es el siguiente:\n",
        "\n",
        "**Nombre,Edad,Ciudad**\n",
        "\n",
        "Ana,30,Madrid\n",
        "\n",
        "Luis,40,Barcelona\n",
        "\n",
        "María,25,Valencia\n",
        "\n",
        "En este caso, observamos que la **Fila 1** contiene los nombres de las columnas (**Encabezados**) y las **filas siguientes** los valores de los datos.\n",
        "\n",
        "A lo largo de las siguientes secciones veremos diversos ejemplos para leer un archivo `csv`,así como las diferentes estrategias cuando estos presentan ciertas características que son necesarias abordar para obtener un `dataframe` apropiado para el AD y el AED.\n",
        "\n"
      ],
      "metadata": {
        "id": "f-im_BlJa2an"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Lectura con diversos símbolos separadores*\n",
        "\n",
        "**Ejemplo 1:** Algunos `csv` emplean diferentes símbolos como separadores.En la siguiente celda se lee un archivo que está separado por comas. Este archivo tiene 6 columnas. Observa que automáticament se asigna un índice a cada fila"
      ],
      "metadata": {
        "id": "y-ot3A6C3oP6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXjoz-shXy6O",
        "outputId": "01b9301b-86db-4d27-c23c-415b04fa43b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      time                                 place magType  mag  \\\n",
            "0  2018-10-13 11:10:23.560         262km NW of Ozernovskiy Rusia     mww  6.7   \n",
            "1  2018-10-13 04:34:15.580            25km E of Bitung Indonesia     mww  5.2   \n",
            "2  2018-10-13 00:13:46.220              42km WNW of Sola Vanuatu     mww  5.7   \n",
            "3  2018-10-12 21:09:49.240  13km E of Nueva Concepcion Guatemala     mww  5.7   \n",
            "4  2018-10-12 02:52:03.620    128km SE of Kimbe Papua New Guinea     mww  5.6   \n",
            "\n",
            "   alert  tsunami  \n",
            "0  green        1  \n",
            "1  green        0  \n",
            "2  green        0  \n",
            "3  green        0  \n",
            "4  green        1  \n"
          ]
        }
      ],
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex01.csv\")\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Ejemplo 2:** Para la lectura de una archivo que utiliza como seperador el punto y coma es necesario indicar en la instrucción dicho símbolo. En caso de no hacerlo el archivo cargado no se ajustará a lo esperado.\n",
        "\n",
        "Para indicar el símbolo separador se usa el parámetro `sep`, el cual, es una variable que almacena el símbolo o también una expresión regular.\n",
        "\n",
        "En el siguiente ejemplo ejecuta la versión en la que se indica el separador y posteriormente en la que se omite. Observa lo que sucede y apoyate de la instrucción `df.shape`."
      ],
      "metadata": {
        "id": "6w6n6XyzTBhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene punto y coma\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex02.csv\",sep=';')\n",
        "\n",
        "#No se indica el separador\n",
        "#df = pd.read_csv(\"drive/MyDrive/Unidad02/ex02.csv\")\n",
        "\n",
        "#imprimimos las primeras 3 filas\n",
        "print(df.head(3))\n",
        "#df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5AV0KVQUA4A",
        "outputId": "a1db219b-dc85-44b6-c434-248918245e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      time                            place magType  mag  \\\n",
            "0  2018-10-13 11:10:23.560  262km NW of Ozernovskiy, Russia     mww  6.7   \n",
            "1  2018-10-13 04:34:15.580      25km E of Bitung, Indonesia     mww  5.2   \n",
            "2  2018-10-13 00:13:46.220        42km WNW of Sola, Vanuatu     mww  5.7   \n",
            "\n",
            "   alert  tsunami  \n",
            "0  green        1  \n",
            "1  green        0  \n",
            "2  green        0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Ejemplo 3:** Otra situación es que el separador es el espacio en blanco. Sin embargo, debido a que puede ser uno o varios espacios en blancos, es posible apoyarse en las expresiones regulares para indicar en `sep` esta situación.\n",
        "\n",
        "El archivo ex03.csv contiene los siguientes elementos. En el código que se proporciona se escribe una expresión regular para indicar que el separador puede ser uno o más espacios en blanco (`\\s+`).\n",
        "\n",
        "En la siguiente imagen se muestra el contenido del archivo `ex03.csv`.\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "JXILB9BrWuou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex03.csv\", sep=\"\\s+\")\n",
        "\n",
        "#imprimimos las primeras 3 filas\n",
        "print(df.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WMqZ0UQYmoP",
        "outputId": "0014d439-140b-4d29-8308-f87797713d44"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     A         B         C         D\n",
            "0  aaa -0.264438 -1.026059 -0.619500\n",
            "1  bbb  0.927272  0.302904 -0.032399\n",
            "2  ccc -0.264273 -0.386314 -0.217601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 4:** Es posible que el archivo csv tenga múltiples separadores. Para ello, usamos también las expresiones regulares.\n",
        "\n",
        "El archivo ex06.csv contiene la siguiente información:\n",
        "\n",
        "ID|Nombre;Edad,Ciudad\n",
        "1|Ana;23,Madrid\n",
        "2|Luis;30,Barcelona\n",
        "3|María;25,Valencia\n",
        "\n",
        "Aquì hay tres tipos de separadores diferentes: `|`, `;` y `,`. Veamos el ejemplo:"
      ],
      "metadata": {
        "id": "o4XlAvHRNVYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex06.csv\", sep=\"[\\|,;]\", engine=\"python\")\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjFbMYlJN5gs",
        "outputId": "da4d6a61-177b-47cd-80e1-4a14f41d51e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID Nombre  Edad     Ciudad\n",
            "0   1    Ana    23     Madrid\n",
            "1   2   Luis    30  Barcelona\n",
            "2   3  María    25   Valencia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Encabezados*\n",
        "\n",
        "En AD, AED y Machine Learning, siempre es deseable que los archivos tengan una fila (encabezado) que representa los nombres de cada columna (variable). Sin embargo, esto a veces no es así. Por lo tanto es importante especificar que el archivo no tiene un encabezado. Esto se hace por medio de `header=None`.\n",
        "\n",
        "\n",
        "**Ejemplo 1:** En el siguiente ejemplo ejecuta la versión donde se indica que no existe un encabezado y la otra donde se omite. Observa lo que sucede."
      ],
      "metadata": {
        "id": "xNN7TI7qeVIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex04.csv\", header=None)\n",
        "\n",
        "#No se especifica que el archivo no contiene un encabezado\n",
        "#df = pd.read_csv(\"drive/MyDrive/Unidad02/ex04.csv\")\n",
        "\n",
        "#imprimimos las primeras 3 filas\n",
        "print(df.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRr62gB9fcf5",
        "outputId": "67ce6a8e-0a26-4e4d-a5b3-3054221ac605"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         0                              1    2    3      4  5\n",
            "0  2018-10-13 11:10:23.560  262km NW of Ozernovskiy Rusia  mww  6.7  green  1\n",
            "1  2018-10-13 04:34:15.580     25km E of Bitung Indonesia  mww  5.2  green  0\n",
            "2  2018-10-13 00:13:46.220       42km WNW of Sola Vanuatu  mww  5.7  green  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Ejemplo 2:** Si no queremos que Pandas le asigne un nombre por default a las columnas, entonces, podemos especificar los nombres por medio del parámetro `names=lista`. En este caso, se omite el parámetro `header`.\n",
        "\n",
        "En el siguiente ejemplo se muestran dos formas de hacer lo anterior."
      ],
      "metadata": {
        "id": "8TYQeQKCrkVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Primera version\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex04.csv\",\n",
        "                 names=[\"time\",\"place\",\"magType\",\"mag\",\"alert\",\"tsunami\"])\n",
        "\n",
        "#Segunda versión - declaramos una variable de tipo lista con los nombres\n",
        "#mynames=[\"time\",\"place\",\"magType\",\"mag\",\"alert\",\"tsunami\"]\n",
        "#df = pd.read_csv(\"drive/MyDrive/Unidad02/ex04.csv\", names=mynames)\n",
        "\n",
        "\n",
        "#imprimimos las primeras 3 filas\n",
        "print(df.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_gT50IQsY4z",
        "outputId": "87e8dc3f-d7f5-47a7-cb26-1c894800398c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      time                          place magType  mag  alert  \\\n",
            "0  2018-10-13 11:10:23.560  262km NW of Ozernovskiy Rusia     mww  6.7  green   \n",
            "1  2018-10-13 04:34:15.580     25km E of Bitung Indonesia     mww  5.2  green   \n",
            "2  2018-10-13 00:13:46.220       42km WNW of Sola Vanuatu     mww  5.7  green   \n",
            "\n",
            "   tsunami  \n",
            "0        1  \n",
            "1        0  \n",
            "2        0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Ejemplo 3:** Si el csv ya tiene encabezados, puedes omitir el encabezado original y usar los nueevos nombres. Para ello, usaremos el parámetro `skiprows=lista con indices de filas a ignorar`.\n",
        "\n",
        "En el siguiente ejemplo leemos er archivo `ex01.csv' que contiene un encabezado.  Crearemos una variable que contendrá los nuevos nombres que sustituirán a los originales y asignamos `skiprows=1`.\n",
        "\n",
        "Ejecuta el código eliminando `skiprows=1` y observa lo que sucede.\n"
      ],
      "metadata": {
        "id": "5M-tcbOH46tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "nuevos_nombres = [\"tiempo_nuevo\",\"lugar_nuevo\",\"tipo_magnitud_nuevo\",\"magnitud_nuevo\",\"alerta_nuevo\",\"tsu_nuevo\"]\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex01.csv\", names = nuevos_nombres,skiprows=1)\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swX9sl4-51fy",
        "outputId": "54816c5a-94b4-46eb-8e87-777b3eaa31e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              tiempo_nuevo                           lugar_nuevo  \\\n",
            "0  2018-10-13 11:10:23.560         262km NW of Ozernovskiy Rusia   \n",
            "1  2018-10-13 04:34:15.580            25km E of Bitung Indonesia   \n",
            "2  2018-10-13 00:13:46.220              42km WNW of Sola Vanuatu   \n",
            "3  2018-10-12 21:09:49.240  13km E of Nueva Concepcion Guatemala   \n",
            "4  2018-10-12 02:52:03.620    128km SE of Kimbe Papua New Guinea   \n",
            "\n",
            "  tipo_magnitud_nuevo  magnitud_nuevo alerta_nuevo  tsu_nuevo  \n",
            "0                 mww             6.7        green          1  \n",
            "1                 mww             5.2        green          0  \n",
            "2                 mww             5.7        green          0  \n",
            "3                 mww             5.7        green          0  \n",
            "4                 mww             5.6        green          1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Ejemplo 4:** Existen conjunto de datos donde el número de columnas es mayor a 2,000. En algunos datos este número puede ser de 54,686,452 (columnas). Vea el caso del conjunto de datos kdd2012 en el repositorio [LIBSVM Data](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#kdd2012).\n",
        "\n",
        "Algunos repositorios proveen un archivo de texto con los nombres de las columnas, en donde, con un nombre por línea. Si esto es así podemos leer dicho archivo de texto y guardar cada nombr en una lista."
      ],
      "metadata": {
        "id": "HEC4hXum8GEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar nombres de columnas desde un archivo de texto\n",
        "with open(\"drive/MyDrive/Unidad02/columnas.txt\", \"r\") as f:\n",
        "    nombres_columnas = [line.strip() for line in f]\n",
        "\n",
        "# Leer el CSV y asignar los nombres\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex04.csv\", names=nombres_columnas, header=None)\n",
        "\n",
        "# Mostrar las primeras filas\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ0VsgER-PF-",
        "outputId": "ed9c4b50-b5e0-432f-c19a-8b214858788c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  time_txt                             place_txt magType_txt  \\\n",
            "0  2018-10-13 11:10:23.560         262km NW of Ozernovskiy Rusia         mww   \n",
            "1  2018-10-13 04:34:15.580            25km E of Bitung Indonesia         mww   \n",
            "2  2018-10-13 00:13:46.220              42km WNW of Sola Vanuatu         mww   \n",
            "3  2018-10-12 21:09:49.240  13km E of Nueva Concepcion Guatemala         mww   \n",
            "4  2018-10-12 02:52:03.620    128km SE of Kimbe Papua New Guinea         mww   \n",
            "\n",
            "   mag_txt alert_txt  tsunami_txt  \n",
            "0      6.7     green            1  \n",
            "1      5.2     green            0  \n",
            "2      5.7     green            0  \n",
            "3      5.7     green            0  \n",
            "4      5.6     green            1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Ejemplo 5:** Una segunda opción es generar los nombres automáticamente con un prefijo y un índice. En el siguiente ejemplo, primero se lee el archivo y posteriormente se modifica los nombres de las columnas con `df.columns`, el cual almacena los nombres de las columnas del `dataframe`.\n",
        "\n",
        "Al hacer `df.columns = [...]`,reemplazamos los nombres originles por los generados"
      ],
      "metadata": {
        "id": "calIxZPb_VAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Leer el CSV sin encabezado\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex04.csv\", header=None)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# Generar nombres de columnas automáticamente\n",
        "#se genera una lista [\"Columna_0\", \"Columna_1\", \"Columna_2\", ..., \"Columna_N\"]\n",
        "df.columns = [f\"MiColumna_{i}\" for i in range(df.shape[1])]\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7bZNnNvAqWq",
        "outputId": "28783f47-617b-41a2-9988-261b9201f8c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         0                                     1    2    3  \\\n",
            "0  2018-10-13 11:10:23.560         262km NW of Ozernovskiy Rusia  mww  6.7   \n",
            "1  2018-10-13 04:34:15.580            25km E of Bitung Indonesia  mww  5.2   \n",
            "2  2018-10-13 00:13:46.220              42km WNW of Sola Vanuatu  mww  5.7   \n",
            "3  2018-10-12 21:09:49.240  13km E of Nueva Concepcion Guatemala  mww  5.7   \n",
            "4  2018-10-12 02:52:03.620    128km SE of Kimbe Papua New Guinea  mww  5.6   \n",
            "\n",
            "       4  5  \n",
            "0  green  1  \n",
            "1  green  0  \n",
            "2  green  0  \n",
            "3  green  0  \n",
            "4  green  1  \n",
            "               MiColumna_0                           MiColumna_1 MiColumna_2  \\\n",
            "0  2018-10-13 11:10:23.560         262km NW of Ozernovskiy Rusia         mww   \n",
            "1  2018-10-13 04:34:15.580            25km E of Bitung Indonesia         mww   \n",
            "2  2018-10-13 00:13:46.220              42km WNW of Sola Vanuatu         mww   \n",
            "3  2018-10-12 21:09:49.240  13km E of Nueva Concepcion Guatemala         mww   \n",
            "4  2018-10-12 02:52:03.620    128km SE of Kimbe Papua New Guinea         mww   \n",
            "\n",
            "   MiColumna_3 MiColumna_4  MiColumna_5  \n",
            "0          6.7       green            1  \n",
            "1          5.2       green            0  \n",
            "2          5.7       green            0  \n",
            "3          5.7       green            0  \n",
            "4          5.6       green            1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*Omitir Filas y Columnas*\n",
        "\n",
        "Pandas permite omitir filas y columnas al leer un archivo CSV usando los parámetros skiprows, skipfooter y usecols.\n",
        "\n",
        "**Ejemplo 1:** Omitir las primeras `n` filas (`skiprows`)\n",
        "Si un archivo CSV tiene filas iniciales innecesarias, puedes ignorarlas con skiprows.\n"
      ],
      "metadata": {
        "id": "5s5vvlPhE2Vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "#Se omiten las 2 primeras filas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex01.csv\", skiprows=2)\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL4aA4nQJVMn",
        "outputId": "8b103fe0-a496-4cf7-f2a5-d2d5b88bfa73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   2018-10-13 04:34:15.580            25km E of Bitung Indonesia  mww  5.2  \\\n",
            "0  2018-10-13 00:13:46.220              42km WNW of Sola Vanuatu  mww  5.7   \n",
            "1  2018-10-12 21:09:49.240  13km E of Nueva Concepcion Guatemala  mww  5.7   \n",
            "2  2018-10-12 02:52:03.620    128km SE of Kimbe Papua New Guinea  mww  5.6   \n",
            "\n",
            "   green  0  \n",
            "0  green  0  \n",
            "1  green  0  \n",
            "2  green  1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 2**: Omitir filas específicas (`skiprows` con lista)\n",
        "\n",
        "Si quieres omitir filas específicas, puedes pasar una lista de índices. En el siguiente ejemplo se omiten las filas 1 y 3 (índices 1 y 3, empezando desde 0)"
      ],
      "metadata": {
        "id": "8FnUyWOHJjD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "# omiten las filas 1 y 3 (índices 1 y 3, empezando desde 0)\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex01.csv\", skiprows=[1,3])\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PimnVQqgJq8d",
        "outputId": "97e66e63-658f-4787-da2b-e11ee4939f55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      time                                 place magType  mag  \\\n",
            "0  2018-10-13 04:34:15.580            25km E of Bitung Indonesia     mww  5.2   \n",
            "1  2018-10-12 21:09:49.240  13km E of Nueva Concepcion Guatemala     mww  5.7   \n",
            "2  2018-10-12 02:52:03.620    128km SE of Kimbe Papua New Guinea     mww  5.6   \n",
            "\n",
            "   alert  tsunami  \n",
            "0  green        0  \n",
            "1  green        0  \n",
            "2  green        1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 3**: Omitir las últimas `n` filas (`skipfooter`)\n",
        "\n",
        "Si el csv tiene datos irrelevantes al final, se puede usar `skipfooter`. En el siguiente ejemplo se omite la última fila.\n",
        "\n",
        "Observa también que se usa el parámetro `engine=\"python\"`, el cual le indica a Pandas que se debe de usar l motor de análisis de archivos de texto de Python, en lugar del motor determinado basado en el lenguaje C.\n",
        "\n"
      ],
      "metadata": {
        "id": "9c16SG6kKeSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "# omiten las filas 1 y 3 (índices 1 y 3, empezando desde 0)\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex01.csv\", skipfooter=1,engine=\"python\")\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br8TP-dpKyTF",
        "outputId": "9806c74f-717d-428c-91b4-9a66e68880c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      time                                 place magType  mag  \\\n",
            "0  2018-10-13 11:10:23.560         262km NW of Ozernovskiy Rusia     mww  6.7   \n",
            "1  2018-10-13 04:34:15.580            25km E of Bitung Indonesia     mww  5.2   \n",
            "2  2018-10-13 00:13:46.220              42km WNW of Sola Vanuatu     mww  5.7   \n",
            "3  2018-10-12 21:09:49.240  13km E of Nueva Concepcion Guatemala     mww  5.7   \n",
            "\n",
            "   alert  tsunami  \n",
            "0  green        1  \n",
            "1  green        0  \n",
            "2  green        0  \n",
            "3  green        0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 4**: Cargar solo columnas específicas (`usecols`)\n",
        "\n",
        "Si el csv tiene muchas columnas pero solo necesitas algunas, podemos usar `usecols`.\n"
      ],
      "metadata": {
        "id": "gJsGlCfULkx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "# Código en Pandas para cargar solo \"magType\",\"mag\",\"tsunami\"\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex01.csv\", usecols=[\"magType\",\"mag\",\"tsunami\"])\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOwE3hBSMgDz",
        "outputId": "98183458-41fd-420d-bbfe-6265de11949a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  magType  mag  tsunami\n",
            "0     mww  6.7        1\n",
            "1     mww  5.2        0\n",
            "2     mww  5.7        0\n",
            "3     mww  5.7        0\n",
            "4     mww  5.6        1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Caracteres Especiales*\n",
        "\n",
        "Algunos archivos csv puden contener caracteres especiales como acento, eñes y otros símbolos. Para evitar problemas al leer dicho archivo o caracteres extraños, se requiere usar el parámetro `encoding=\"utf-8\"`\n",
        "\n",
        "El archivo `ex07.csv`contiene la siguiente información:\n",
        "\n",
        "ID,Nombre,País,Comentario\n",
        "\n",
        "1,Ana,España,\"Estudió en la universidad pública de Madrid\"\n",
        "\n",
        "2,Luis,México,\"Le encanta la programación y la música 🎵\"\n",
        "\n",
        "3,María,Francia,\"Habla francés, inglés y español\"\n",
        "\n",
        "4,José,Brasil,\"Trabaja en São Paulo\"\n",
        "\n",
        "5,Sofía,Alemania,\"Investigadora en física cuántica ⚛️\"\n",
        "\n"
      ],
      "metadata": {
        "id": "pjMkZ0RcOp4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex07.csv\",encoding=\"utf-8\")\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5c17mPoPZKg",
        "outputId": "d49f7a0a-a131-41db-eb7d-d8561eb40511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID Nombre      País                                   Comentario\n",
            "0   1    Ana    España  Estudió en la universidad pública de Madrid\n",
            "1   2   Luis    México     Le encanta la programación y la música 🎵\n",
            "2   3  María   Francia              Habla francés, inglés y español\n",
            "3   4   José    Brasil                         Trabaja en São Paulo\n",
            "4   5  Sofía  Alemania          Investigadora en física cuántica ⚛️\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Valores Perdidos*\n",
        "\n",
        "Cuando los datos se exportan a CSV desde diferentes sistemas, los valores faltantes pueden especificarse con distintos símbolos.\n",
        "\n",
        "Los valores predeterminados que Pandas interpreta como NA/NaN son:\n",
        "`''`, `#N/A`, `#N/A`, `N/A`, `#NA`, `-1.#IND`, `-1.#QNAN`, `-NaN`, `-nan`, `1.#IND`, `1.#QNAN`, `N/A`, `NA`, `NULL`, `NaN`, `n/a`, `nan`, `null`.\n",
        "\n",
        "**Ejemplo 1:** El archivo ex08.csv contiene 3 valores perdidos que se identifican con el valor `NaN` y `??`. Observa que salida produce cuando se emplea la instrucción `pd.isna(df)`"
      ],
      "metadata": {
        "id": "qvMmbGcOPvDf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2sAdSh1lRy2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex08.csv\")\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())\n",
        "\n",
        "#Mostramos las celdas en las que aparece un dato perdido\n",
        "print(pd.isna(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deu6EEk0Rdyg",
        "outputId": "26893c75-df7a-4fa8-cc04-f0f86304d294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  something  a   b     c   d message\n",
            "0       one  1   2   3.0   4     NaN\n",
            "1       two  5  ??   NaN   8   world\n",
            "2     three  9  10  11.0  12     foo\n",
            "   something      a      b      c      d  message\n",
            "0      False  False  False  False  False     True\n",
            "1      False  False  False   True  False    False\n",
            "2      False  False  False  False  False    False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 02:** los caracteres `??` denotan un valor perdido, este no fue detectado como tal. Para que esto ocurra, el parámetro `na_values` permite personalizar la lista de caracteres que se reconocerán como valores faltantes."
      ],
      "metadata": {
        "id": "VMqCu0c-SbDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex08.csv\",na_values=[\"??\"])\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df.head())\n",
        "\n",
        "print(pd.isna(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a1m28IES3lu",
        "outputId": "300fe9db-ac6e-4013-d140-72f75355cdaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  something  a     b     c   d message\n",
            "0       one  1   2.0   3.0   4     NaN\n",
            "1       two  5   NaN   NaN   8   world\n",
            "2     three  9  10.0  11.0  12     foo\n",
            "   something      a      b      c      d  message\n",
            "0      False  False  False  False  False     True\n",
            "1      False  False   True   True  False    False\n",
            "2      False  False  False  False  False    False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Archivos Grandes CSV*\n",
        "\n",
        "Procesar archivos csv grandes en Pandas requiere estrategias avanzadas para optimizar memoria y velocidad. Existen diversas estrategias y aquí veremos algunas de ellas.\n",
        "\n",
        "**Ejemplo 1:** Es posible que tengas la capacidad de cargar el archivo. Sin embargo, al querer imprimir el contenido seguramente tardará y ocupará toda tu pantalla. Una opción es usar la instrucción `pd.options.display.max_rows=número de filas`, la cual se usa para controlar el número máximo de filas que pandas muestra cuando se imprime un `dataframe`.  El efecto de usar esta instrucción es que Pandas trunca la salida si el `dataframe` tiene muchas filas, mostrando solo las primeras y últimas filas con \"...\" en el medio.\n",
        "\n",
        "El archivo ex09.csv contiene 5 columnas y 10,000 Filas. En el siguiente ejemplo `pd.options.display.max_rows=10`.\n"
      ],
      "metadata": {
        "id": "di1BSwrN7KDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "#Limitamos el número de filas a mostrar de las 10,000\n",
        "pd.options.display.max_rows = 10\n",
        "\n",
        "# Leemos el archivo que contiene comas\n",
        "df = pd.read_csv(\"drive/MyDrive/Unidad02/ex09.csv\")\n",
        "\n",
        "#imprimimos el archivo completo\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAitsdTb-6_O",
        "outputId": "ed601b22-e9ac-4ac5-d64e-612b8b8be762"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           one       two     three      four key\n",
            "0     0.467976 -0.038649 -0.295344 -1.824726   L\n",
            "1    -0.358893  1.404453  0.704965 -0.200638   B\n",
            "2    -0.501840  0.659254 -0.421691 -0.057688   G\n",
            "3     0.204886  1.074134  1.388361 -0.982404   R\n",
            "4     0.354628 -0.133116  0.283763 -0.837063   Q\n",
            "...        ...       ...       ...       ...  ..\n",
            "9995  2.311896 -0.417070 -1.409599 -0.515821   L\n",
            "9996 -0.479893 -0.650419  0.745152 -0.646038   E\n",
            "9997  0.523331  0.787112  0.486066  1.093156   K\n",
            "9998 -0.362559  0.598894 -1.843201  0.887292   G\n",
            "9999 -0.096376 -1.012999 -0.657431 -0.573315   0\n",
            "\n",
            "[10000 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 2:** Esta estrategia es muy sencilla y se enfoca en solo leer un parte (muestra) al especificar el número de filas. Esto te permite una rápida inspección sin cargar todo el archivo en memoria.\n",
        "\n",
        "En este ejercicio vamos a trabajar con un archivo conocido como NYC Yellow Taxi Trip Data del 2016. Debido al tamaño de este archivo , 1.91 GB, está alojado en una carpeta de Dropbox."
      ],
      "metadata": {
        "id": "TAhkM6bPAp8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "#una variable que contiene la dirección donde está alojado el archivo\n",
        "url = \"https://www.dropbox.com/scl/fo/x4a4a3jst0z0feb8kedz7/AC-g-Xxv6CmyBaL7jeKpiEo?rlkey=pmrtbg5qlxrq397f9lcxfr6iw&dl=1\"\n",
        "\n",
        "df = pd.read_csv(url, nrows=100, sep=',', encoding=\"utf-8\")  # Leer solo 100 filas\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhgBJIbODSa5",
        "outputId": "48435434-3173-42a6-e783-16e41d7f7c42"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PK\u0003\u0004\u0014 tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
            "0      1  2016-03-01 00:00:00   2016-03-01 00:07:55                1   \n",
            "1      1  2016-03-01 00:00:00   2016-03-01 00:11:06                1   \n",
            "2      2  2016-03-01 00:00:00   2016-03-01 00:31:06                2   \n",
            "3      2  2016-03-01 00:00:00   2016-03-01 00:00:00                3   \n",
            "4      2  2016-03-01 00:00:00   2016-03-01 00:00:00                5   \n",
            "\n",
            "   trip_distance  pickup_longitude  pickup_latitude  RatecodeID  \\\n",
            "0           2.50        -73.976746        40.765152           1   \n",
            "1           2.90        -73.983482        40.767925           1   \n",
            "2          19.98        -73.782021        40.644810           1   \n",
            "3          10.78        -73.863419        40.769814           1   \n",
            "4          30.43        -73.971741        40.792183           3   \n",
            "\n",
            "  store_and_fwd_flag  dropoff_longitude  dropoff_latitude  payment_type  \\\n",
            "0                  N         -74.004265         40.746128             1   \n",
            "1                  N         -74.005943         40.733166             1   \n",
            "2                  N         -73.974541         40.675770             1   \n",
            "3                  N         -73.969650         40.757767             1   \n",
            "4                  N         -74.177170         40.695053             1   \n",
            "\n",
            "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
            "0          9.0    0.5      0.5        2.05          0.00   \n",
            "1         11.0    0.5      0.5        3.05          0.00   \n",
            "2         54.5    0.5      0.5        8.00          0.00   \n",
            "3         31.5    0.0      0.5        3.78          5.54   \n",
            "4         98.0    0.0      0.0        0.00         15.50   \n",
            "\n",
            "   improvement_surcharge  total_amount  \n",
            "0                    0.3         12.35  \n",
            "1                    0.3         15.35  \n",
            "2                    0.3         63.80  \n",
            "3                    0.3         41.62  \n",
            "4                    0.3        113.80  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 2:** Leer en bloques (`chunksize`), por lo que, en lugar de cargar el archivo completo, Pandas permite procesarlo en bloques más pequeños, evitando el colapso de memoria."
      ],
      "metadata": {
        "id": "8uXl1rugJbeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "chunk_size = 1000  # Tamaño del bloque\n",
        "\n",
        "# Leer el archivo en bloques\n",
        "\n",
        "for chunk in pd.read_csv(\"drive/MyDrive/Unidad02/ex09.csv\", sep=',', encoding=\"utf-8\", chunksize=chunk_size):\n",
        "  print(f\"Procesando bloque de {chunk_size} filas:\")\n",
        "  print(chunk.head())\n",
        "  print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74iVFTnTJrWl",
        "outputId": "adffbc19-5cdd-4fd4-fb6e-cb20e6eca314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando bloque de 1000 filas:\n",
            "        one       two     three      four key\n",
            "0  0.467976 -0.038649 -0.295344 -1.824726   L\n",
            "1 -0.358893  1.404453  0.704965 -0.200638   B\n",
            "2 -0.501840  0.659254 -0.421691 -0.057688   G\n",
            "3  0.204886  1.074134  1.388361 -0.982404   R\n",
            "4  0.354628 -0.133116  0.283763 -0.837063   Q\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "1000  0.467976 -0.038649 -0.295344 -1.824726   T\n",
            "1001 -0.358893  1.404453  0.704965 -0.200638   J\n",
            "1002 -0.501840  0.659254 -0.421691 -0.057688   R\n",
            "1003  0.204886  1.074134  1.388361 -0.982404   S\n",
            "1004  0.354628 -0.133116  0.283763 -0.837063   B\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "2000  0.467976 -0.038649 -0.295344 -1.824726   1\n",
            "2001 -0.358893  1.404453  0.704965 -0.200638   H\n",
            "2002 -0.501840  0.659254 -0.421691 -0.057688   F\n",
            "2003  0.204886  1.074134  1.388361 -0.982404   L\n",
            "2004  0.354628 -0.133116  0.283763 -0.837063   E\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "3000  0.467976 -0.038649 -0.295344 -1.824726   H\n",
            "3001 -0.358893  1.404453  0.704965 -0.200638   Y\n",
            "3002 -0.501840  0.659254 -0.421691 -0.057688   0\n",
            "3003  0.204886  1.074134  1.388361 -0.982404   Z\n",
            "3004  0.354628 -0.133116  0.283763 -0.837063   U\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "4000  0.467976 -0.038649 -0.295344 -1.824726   H\n",
            "4001 -0.358893  1.404453  0.704965 -0.200638   Z\n",
            "4002 -0.501840  0.659254 -0.421691 -0.057688   2\n",
            "4003  0.204886  1.074134  1.388361 -0.982404   B\n",
            "4004  0.354628 -0.133116  0.283763 -0.837063   1\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "5000  0.467976 -0.038649 -0.295344 -1.824726   1\n",
            "5001 -0.358893  1.404453  0.704965 -0.200638   Z\n",
            "5002 -0.501840  0.659254 -0.421691 -0.057688   3\n",
            "5003  0.204886  1.074134  1.388361 -0.982404   H\n",
            "5004  0.354628 -0.133116  0.283763 -0.837063   B\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "6000  0.467976 -0.038649 -0.295344 -1.824726   I\n",
            "6001 -0.358893  1.404453  0.704965 -0.200638   X\n",
            "6002 -0.501840  0.659254 -0.421691 -0.057688   A\n",
            "6003  0.204886  1.074134  1.388361 -0.982404   C\n",
            "6004  0.354628 -0.133116  0.283763 -0.837063   S\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "7000  0.467976 -0.038649 -0.295344 -1.824726   1\n",
            "7001 -0.358893  1.404453  0.704965 -0.200638   I\n",
            "7002 -0.501840  0.659254 -0.421691 -0.057688   H\n",
            "7003  0.204886  1.074134  1.388361 -0.982404   P\n",
            "7004  0.354628 -0.133116  0.283763 -0.837063   D\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "8000  0.467976 -0.038649 -0.295344 -1.824726   7\n",
            "8001 -0.358893  1.404453  0.704965 -0.200638   W\n",
            "8002 -0.501840  0.659254 -0.421691 -0.057688   C\n",
            "8003  0.204886  1.074134  1.388361 -0.982404   S\n",
            "8004  0.354628 -0.133116  0.283763 -0.837063   H\n",
            "\n",
            "\n",
            "Procesando bloque de 1000 filas:\n",
            "           one       two     three      four key\n",
            "9000  0.467976 -0.038649 -0.295344 -1.824726   B\n",
            "9001 -0.358893  1.404453  0.704965 -0.200638   M\n",
            "9002 -0.501840  0.659254 -0.421691 -0.057688   N\n",
            "9003  0.204886  1.074134  1.388361 -0.982404   N\n",
            "9004  0.354628 -0.133116  0.283763 -0.837063   Y\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Excel**\n",
        "En esta sesión aprenderemos a cargar, explorar y manipular archivos Excel (`.xlsx`, `.xls`) en Pandas.\n",
        "\n",
        "Es posible que para poder leer archivos `.xlsx` se requiera instalar la biblioteca `openpyxl` y en el caso de `.xls` sería `xlrd`. Si esto sucede, recuerda que para instalar ambas bibliotecas en Google Colab se tendrían que ejecutar las instrucciones siguientes:\n",
        "\n",
        "\n",
        "```python\n",
        "#para .xlsx\n",
        "!pip install openpyxl\n",
        "```\n",
        "y\n",
        "\n",
        "```python\n",
        "#para .xls\n",
        "!pip install xlrd\n",
        "```\n",
        "\n",
        "Existen dos funciones para leer archivos de Excel:\n",
        "\n",
        "\n",
        "\n",
        "1.  `pd.read_excel()` es la forma más común de leer un archivo Excel en un DataFrame. **Es fácil, directo y se usa cuando solo necesitar leer una o pocas hojas**. Sin embargo, si el archivo **tiene varias hojas**, esta función **vuelve a abrir el archivo cada vez que se usa**, lo que hace **lento el proceso de carga**.\n",
        "\n",
        "2.  `pd.ExcelFile()`, es **apropiado** si el archivo Excel tiene **varias hojas**, en lugar de abrirlo múltiples veces, **abre una vez**, por lo que es posible **extraer múltiples hojas sin volver a cargar el archivo**. No obstante, **requiere un paso extra** (`xls.parse(sheet_name)`) para **leer cada hoja** en un `dataframe`.\n",
        "\n",
        "En los siguientes ejemplos vamos a usar el archivo `ex10.xls` y `ex11.xlsx`. Ambos son iguales, contienen 4 hojas, donde `Hoja1` y `Hoja2` contienes una tabla sencilla, `source` contiene 2 celdas que indican la fuente de la información de la tercera hoja llamada `OECD.Stat export`. Esta última, es una hoja con colores y celdas que no contienen información, así como otras configuraciones que son habituales en hojas de `Excel`."
      ],
      "metadata": {
        "id": "xH1Q4hzmKp9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *`pandas.read_excel()`: Leer Directamente un Archivo*\n",
        "\n",
        "`pd.read_excel()` es la forma más común de leer un archivo Excel, principalmente si solo tiene una o pocas hojas. Esta función requiere el parámetro `sheet_name = nombre de la hoja`, para indicar el nombre de la hoja que queremos leer. Si el archivo tiene varias hojas y no se especifica este parámetro, entonces sólo se leera la primera hoja por defecto.\n",
        "\n",
        "Si quieres cargar todas las hojas en un solo paso, entonces, deberás usar el parámetro `sheet_name = None`. Sin embargo, observa que esto no devuelve un `dataframe` sino una `variable` de tipo `diccionario`, donde las `claves`son los nombres de las hojas y los `valores`los dataframes de cada hoja.\n",
        "\n",
        "Para imprimir las hojas disponibles, se usa `variablediccionario.keys()`, la cual retornará un diccionario con el nombre clave de cada hoja. Para acceder al contenido de cada una de ellas, usamos la función `variablediccionario[\"nombre de la hoja\"]`.\n",
        "\n",
        "**Ejemplo 1:** El siguiente código ejemplifica lo siguiente: 1) se especifica el nombre de la hoja, 2)indica la columna que contiene el índice, 3) leer todas las hojas, 4) indicar qué columnas se quieren leer."
      ],
      "metadata": {
        "id": "uWUt5Lr3kPga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#---------------- 1)\n",
        "#OJO: aquí df es un dataframe\n",
        "df = pd.read_excel(\"drive/MyDrive/Unidad02/ex10.xls\", sheet_name=\"Hoja1\")\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "#---------------- 2)\n",
        "#Como esta tabla tiene una primera columna que representa el índice\n",
        "#podemos especificar con index_col el número de columna que sea\n",
        "#indice.\n",
        "#Ejecuta el siguiente código\n",
        "#Aquí df es un dataframe\n",
        "#df = pd.read_excel(\"drive/MyDrive/Unidad02/ex10.xls\", sheet_name=\"Hoja1\", index_col=0)\n",
        "\n",
        "#imprime la hoja 1\n",
        "#print(df.head())\n",
        "\n",
        "#--------------------------- 3)\n",
        "#Para leer todas las hojas usa sheet_name=None.\n",
        "#Recuerda que si no usas este parámetro solo leerá la primera hoja\n",
        "#Nota: hojas no es un dataframe sino un diccionario\n",
        "#hojas = pd.read_excel(\"drive/MyDrive/Unidad02/ex10.xls\", sheet_name=None)\n",
        "\n",
        "#imprime los nombres de todas las hojas\n",
        "#print(hojas.keys())\n",
        "\n",
        "#Se almacena en un data frame la Hoja2 (nombre)\n",
        "#df_hoja2 = hojas[\"Hoja2\"]\n",
        "#print(df_hoja2)\n",
        "\n",
        "\n",
        "#------------------- 4)\n",
        "#podemos leeer ciertas columnas\n",
        "\n",
        "#df = pd.read_excel(\"drive/MyDrive/Unidad02/ex10.xls\", sheet_name=\"Hoja2\", usecols=[\"B\", \"D\"])\n",
        "#print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVgqhKzCoK2l",
        "outputId": "77234d26-938a-44e0-e7f5-63c53854570c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  a   b   c   d message\n",
            "0           0  1   2   3   4   hello\n",
            "1           1  5   6   7   8   world\n",
            "2           2  9  10  11  12     foo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *`pandas.ExcelFile()`: Para Leer Varias Hojas*\n",
        "\n",
        "Si el archivo Excel tiene varias hojas, en lugar de abrirlo múltiples veces, `ExcelFile` permite abrirlo una vez y extraer múltiples hojas sin volver a cargar el archivo.\n",
        "\n",
        " `pandas.ExcelFile()` abre un archivo de Excel en un objeto. No carga todas las hojas de inmediata, solo prepara el archivo para acceder a sus hojas cuando sea necesario. Para ello, se usa `.parse(sheet_name)`que permite extraer las hojas individuales y convertirla en un `dataframe`.\n",
        "\n",
        " **Ejemplo 02:** Veremos como accedemos a las hojas del archivo `ex11.xlsx`."
      ],
      "metadata": {
        "id": "oYAFvPDSt1VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "xlsx = pd.ExcelFile(\"drive/MyDrive/Unidad02/ex10.xls\")\n",
        "\n",
        "#imprimos las hojas disponibles\n",
        "print(xlsx.sheet_names)\n",
        "\n",
        "#Leemos la primera hoja llamada Hoja1 e indicamos qué columna usar como índice\n",
        "\n",
        "df=xlsx.parse(sheet_name=\"Hoja1\", index_col=0)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "#La segunda hoja\n",
        "df=xlsx.parse(sheet_name=\"Hoja2\", usecols=[\"B\", \"D\"])\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjGRyn2WsFf0",
        "outputId": "c0b538fa-e203-44d5-c332-934ff3186b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hoja1', 'Hoja2', 'Source', 'OECD.Stat export']\n",
            "   a   b   c   d message\n",
            "0  1   2   3   4   hello\n",
            "1  5   6   7   8   world\n",
            "2  9  10  11  12     foo\n",
            "          B         D\n",
            "0 -0.264438 -0.619500\n",
            "1  0.927272 -0.032399\n",
            "2 -0.264273 -0.217601\n",
            "3 -0.871858  1.100491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Ejemplo con hojas complejas*\n",
        "En esta receta, importamos un archivo de Excel y abordamos algunos problemas comunes al trabajar con estos archivos: información extra en encabezados y pies de página, selección de columnas específicas, eliminación de filas sin datos y conexión a hojas en particular.\n",
        "\n",
        "A pesar de la estructura tabular de Excel, que fomenta la organización de datos en filas y columnas, las hojas de cálculo no son conjuntos de datos y no requieren que las personas almacenen la información de esa manera. Incluso cuando algunos datos cumplen con esta estructura, es común encontrar información adicional en filas o columnas antes o después de los datos a importar. Además, los tipos de datos no siempre son evidentes para quien no creó la hoja de cálculo.\n",
        "\n",
        "Los que haremos es lo siguiente:\n",
        "\n",
        "- Seleccionaremos la hoja con los datos que necesitamos, pero omiteremos las columnas y filas que no queremos. Usaremos el parámetro `sheet_name` para especificar la hoja.\n",
        "\n",
        "- Emplearemos `skiprows=4` y `skipfooter=1` para omitir las primeras cuatro filas (la primera fila está oculta) y la última fila, respectivamente.\n",
        "\n",
        "- Usaremos `usecols` para obtener datos de la columna A y de las columnas C a W (la columna B está en blanco).\n",
        "- También `head` para ver las primeras filas y `shape` para obtener el número de filas y columnas.\n"
      ],
      "metadata": {
        "id": "lmxOwljZxBTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería de pandas y asignamos un alias (pd)\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(\"drive/MyDrive/Unidad02/ex11.xlsx\",\n",
        "                   sheet_name=\"OECD.Stat export\",\n",
        "                   skiprows=4,\n",
        "                   skipfooter=1,\n",
        "                   usecols=\"A,C:T\")\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTtWE61cyzlE",
        "outputId": "fe881ac6-1e72-4440-d4e2-753a4b6839aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         Year   2001   2002   2003   2004   2005   2006  \\\n",
            "0          Metropolitan areas    NaN    NaN    NaN    NaN    NaN    NaN   \n",
            "1              AUS: Australia     ..     ..     ..     ..     ..     ..   \n",
            "2       AUS01: Greater Sydney  43313  44008  45424  45837  45423  45547   \n",
            "3    AUS02: Greater Melbourne  40125  40894  41602  42188  41484  41589   \n",
            "4     AUS03: Greater Brisbane  37580  37564  39080  40762  42976  44475   \n",
            "\n",
            "    2007   2008   2009   2010   2011   2012   2013   2014   2015   2016  \\\n",
            "0    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
            "1     ..     ..     ..     ..     ..     ..     ..     ..     ..     ..   \n",
            "2  45880  45225  45900  45672  46535  47350  47225  48510  50075  50519   \n",
            "3  42316  40975  41384  40943  41165  41264  41157  42114  42928  42671   \n",
            "4  44635  46192  43507  42774  44166  43764  43379  43754  44388  45723   \n",
            "\n",
            "    2017   2018  \n",
            "0    NaN    NaN  \n",
            "1     ..     ..  \n",
            "2  50578  49860  \n",
            "3  43025  42674  \n",
            "4  46876  46640  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importar Datos desde Bases de Datos SQL**\n",
        "\n",
        "En este ejemplo, utilizamos las API de pymssql y mysql para leer datos desde bases de datos Microsoft SQL Server y MySQL. También es posible que se requiera instalar ambas API.\n",
        "\n",
        "No profundizaremos en este tema porque require aspectos de Ingeniería de Datos y SQL\n",
        "\n",
        "En este ejercicio nos conectaremos a una base de datos que está en la nube. Para extraer los datos usaremos una consulta SQL\n",
        "\n"
      ],
      "metadata": {
        "id": "hbUuo7Wo1psk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymssql"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4l7GDjch0-Nb",
        "outputId": "d12c44f5-725b-49b8-c21e-0ffbb03a8caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymssql\n",
            "  Downloading pymssql-2.3.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.7 kB)\n",
            "Downloading pymssql-2.3.2-cp311-cp311-manylinux_2_28_x86_64.whl (4.8 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m4.4/4.8 MB\u001b[0m \u001b[31m133.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymssql\n",
            "Successfully installed pymssql-2.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install mysql-connector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mbnIn3l_1G1y",
        "outputId": "a9656657-2bdd-49bd-b304-bfa3f9e98120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mysql-connector\n",
            "  Downloading mysql-connector-2.2.9.tar.gz (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mysql-connector\n",
            "  Building wheel for mysql-connector (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysql-connector: filename=mysql_connector-2.2.9-cp311-cp311-linux_x86_64.whl size=247949 sha256=5a2d7fb29dbe3cf88c1746ac03a1949f1111652e86748b6f579c0c6ac6ac83c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/cd/ed/2d49e9bac69cf09382e4c7cc20a2511202b48324b87db26019\n",
            "Successfully built mysql-connector\n",
            "Installing collected packages: mysql-connector\n",
            "Successfully installed mysql-connector-2.2.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Importación de bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pymssql\n",
        "import mysql.connector\n",
        "\n",
        "# Consulta SQL que selecciona datos de la tabla studentmath.\n",
        "query = \"SELECT studentid, school, sex, age, famsize,\\\n",
        "  medu AS mothereducation, fedu AS fathereducation,\\\n",
        "  traveltime, studytime, failures, famrel, freetime,\\\n",
        "  goout, g1 AS gradeperiod1, g2 AS gradeperiod2,\\\n",
        "  g3 AS gradeperiod3 From studentmath\"\n",
        "\n",
        "#Conexión a la base de datos SQL Server\n",
        "# use the pymssql api and read_sql to retrieve and load data from a SQL Server instance\n",
        "server = \"pdcc.c9sqqzd5fulv.us-west-2.rds.amazonaws.com\"\n",
        "user = \"pdccuser\"\n",
        "password = \"pdccpass\"\n",
        "database = \"pdcctest\"\n",
        "\n",
        "#Se establece la conexión a una base de datos SQL Server en la nube\n",
        "conn = pymssql.connect(server=server,\n",
        "                       user=user, password=password, database=database)\n",
        "\n",
        "#Ejecución de la consulta y carga en un DataFrame\n",
        "studentmath = pd.read_sql(query,conn)\n",
        "\n",
        "#cierra la conexión con la base de datos después de obtener los datos\n",
        "conn.close()\n",
        "\n",
        "#imprimimos el dataframe\n",
        "print(studentmath.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__K5xqc70ytQ",
        "outputId": "f06bfa11-5ebd-4788-9eee-071cf55c6e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-cd20bbcfffd5>:26: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  studentmath = pd.read_sql(query,conn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  studentid school sex  age famsize  mothereducation  fathereducation  \\\n",
            "0       001     GP   F   18     GT3                4                4   \n",
            "1       002     GP   F   17     GT3                1                1   \n",
            "2       003     GP   F   15     LE3                1                1   \n",
            "3       004     GP   F   15     GT3                4                2   \n",
            "4       005     GP   F   16     GT3                3                3   \n",
            "\n",
            "   traveltime  studytime  failures  famrel  freetime  goout  gradeperiod1  \\\n",
            "0           2          2         0       4         3      4             5   \n",
            "1           1          2         0       5         3      3             5   \n",
            "2           1          2         3       4         3      2             7   \n",
            "3           1          3         0       3         2      2            15   \n",
            "4           1          2         0       4         3      2             6   \n",
            "\n",
            "   gradeperiod2  gradeperiod3  \n",
            "0             6             6  \n",
            "1             5             6  \n",
            "2             8            10  \n",
            "3            14            15  \n",
            "4            10            10  \n"
          ]
        }
      ]
    }
  ]
}